%  template.tex for Biometrics papers
%
%  This file provides a template for Biometrics authors.  Use this
%  template as the starting point for creating your manuscript document.
%  See the file biomsample.tex for an example of a full-blown manuscript.

%  ALWAYS USE THE referee OPTION WITH PAPERS SUBMITTED TO BIOMETRICS!!!
%  You can see what your paper would look like typeset by removing
%  the referee option.  Because the typeset version will be in two
%  columns, however, some of your equations may be too long. DO NOT
%  use the \longequation option discussed in the user guide!!!  This option
%  is reserved ONLY for equations that are impossible to split across 
%  multiple lines; e.g., a very wide matrix.  Instead, type your equations 
%  so that they stay in one column and are split across several lines, 
%  as are almost all equations in the journal.  Use a recent version of the
%  journal as a guide. 
%  
%\documentclass[12pt]{article}
\documentclass[useAMS,usenatbib,referee]{biom}
%documentclass[useAMS]{biom}
%
%  If your system does not have the AMS fonts version 2.0 installed, then
%  remove the useAMS option.
%
%  useAMS allows you to obtain upright Greek characters.
%  e.g. \umu, \upi etc.  See the section on "Upright Greek characters" in
%  this guide for further information.
%
%  If you are using AMS 2.0 fonts, bold math letters/symbols are available
%  at a larger range of sizes for NFSS release 1 and 2 (using \boldmath or
%  preferably \bmath).
% 
%  Other options are described in the user guide. Here are a few:
% 
%  -  If you use Patrick Daly's natbib  to cross-reference your 
%     bibliography entries, use the usenatbib option
%
%  -  If you use \includegraphics (graphicx package) for importing graphics
%     into your figures, use the usegraphicx option
% 
%  If you wish to typeset the paper in Times font (if you do not have the
%  PostScript Type 1 Computer Modern fonts you will need to do this to get
%  smoother fonts in a PDF file) then uncomment the next line
%  \usepackage{Times}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{xfrac}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{url} % not crucial - just used below for the URL
\usepackage{float}
\usepackage[T1]{fontenc}
\usepackage{colortbl}
\usepackage{rotating}

%\usepackage{biblatex}
%\usepackage{harvard}


%%%%%%%%%%%%%%%%%%%% MACROS %%%%%%%%%%%%%%%%%
\def\bSig\mathbf{\Sigma}
\newcommand{\VS}{V\&S}
\newcommand{\tr}{\mbox{tr}}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
%
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother

%  The rotating package allows you to have tables displayed in landscape
%  mode.  The rotating package is NOT included in this distribution, but
%  can be obtained from the CTAN archive.  USE OF LANDSCAPE TABLES IS
%  STRONGLY DISCOURAGED -- create landscape tables only as a last resort if
%  you see no other way to display the information.  If you do do this,
%  then you need the following command.

%\usepackage[figuresright]{rotating}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%  Here, place your title and author information.  Note that in
%  use of the \author command, you create your own footnotes.  Follow
%  the examples below in creating your author and affiliation information.
%  Also consult a recent issue of the journal for examples of formatting.

\title[NTS:NEED TO ADD TCGA BRCA AND BLCA IN BIBLIO]{Model-based Simultaneous Feature Selection and Clustering of Raw RNA-seq Data for Subtype Discovery}

%  Here are examples of different configurations of author/affiliation
%  displays.  According to the Biometrics style, in some instances,
%  the convention is to have superscript *, **, etc footnotes to indicate
%  which of multiple email addresses belong to which author.  In this case,
%  use the \email{ } command to produce the emails in the display.

%  In other cases, such as a single author or two authors from
%  different institutions, there should be no footnoting.  Here, use
%  the \emailx{ } command instead.

%  The examples below corrspond to almost every possible configuration
%  of authors and may be used as a guide.  For other configurations, consult
%  a recent issue of the the journal.

%  Single author -- USE \emailx{ } here so that no asterisk footnoting
%  for the email address will be produced.

%\author{John Author\emailx{email@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.}

%  Two authors from the same institution, with both emails -- use
%  \email{ } here to produce the asterisk footnoting for each email address

%\author{John Author$^{*}$\email{author@address.edu} and
%Kathy Authoress$^{**}$\email{email2@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.}

%  Exactly two authors from different institutions, with both emails
%  USE \emailx{ } here so that no asterisk footnoting for the email address
%  is produced.

% \author
% {John Author\emailx{author@address.edu} \\
% Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.
% \and
% Kathy Author\emailx{anotherauthor@address.edu} \\
% Department of Biostatistics, University of North Carolina at Chapel Hill,
% Chapel Hill, North Carolina, U.S.A.}

%  Three or more authors from same institution with all emails displayed
%  and footnoted using asterisks -- use \email{ }

\author{David Lim$^*$\email{deelim@ad.unc.edu},
Naim Rashid$^{**}$\email{naim@unc.edu}, and
Joseph Ibrahim$^{***}$\email{ibrahim@bios.unc.edu} \\
Department of Biostatistics, University of North Carolina, Chapel Hill, NC, USA}

%  Three or more authors from same institution with one corresponding email
%  displayed

%\author{John Author$^*$\email{author@address.edu}, 
%Jane Author, and Dick Author \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K}

%  Three or more authors, with at least two different institutions,
%  more than one email displayed 

%\author{John Author$^{1,*}$\email{author@address.edu}, 
%Kathy Author$^{2,**}$\email{anotherauthor@address.edu}, and 
%Wilma Flinstone$^{3,***}$\email{wilma@bedrock.edu} \\
%$^{1}$Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K \\
%$^{2}$Department of Biostatistics, University of North Carolina at 
%Chapel Hill, Chapel Hill, North Carolina, U.S.A. \\
%$^{3}$Department of Geology, University of Bedrock, Bedrock, Kansas, U.S.A.}

%  Three or more authors with at least two different institutions and only
%  one email displayed

%\author{John Author$^{1,*}$\email{author@address.edu}, 
%Wilma Flinstone$^{2}$, and Barney Rubble$^{2}$ \\
%$^{1}$Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K \\
%$^{2}$Department of Geology, University of Bedrock, Bedrock, Kansas, U.S.A.}

\begin{document}
\SweaveOpts{concordance=TRUE}

% \setlength{\paperheight}{11in}
% \setlength{\paperwidth}{8.5in}


% \date{{\it Received October} 2007. {\it Revised February} 2008.  {\it
% Accepted March} 2008.}

%  These options will count the number of pages and provide volume
%  and date information in the upper left hand corner of the top of the 
%  first page as in published papers.  The \pagerange command will only
%  work if you place the command \label{firstpage} near the beginning
%  of the document and \label{lastpage} at the end of the document, as we
%  have done in this template.

%  Again, putting a volume number and date is for your own amusement and
%  has no bearing on what actually happens to your paper!  

\pagerange{\pageref{firstpage}--\pageref{lastpage}} 
% \volume{64}
% \pubyear{2008}
% \artmonth{December}

%  The \doi command is where the DOI for your paper would be placed should it
%  be published.  Again, if you make one up and stick it here, it means 
%  nothing!

% \doi{10.1111/j.1541-0420.2005.00454.x}

%  This label and the label ``lastpage'' are used by the \pagerange
%  command above to give the page range for the article.  You may have 
%  to process the document twice to get this to match up with what you 
%  expect.  When using the referee option, this will not count the pages
%  with tables and figures.  

\label{firstpage}

%  put the summary for your paper here

%% BLINDING %%
% \if1\blind
% {
%   \title{\bf Mixture Negative Binomial Expectation Maximization (NB-EM) Algorithm for Unsupervised Clustering}
%   \author{David Lim\thanks{
%     The authors gratefully acknowledge \textit{please remember to list all relevant funding sources in the unblinded version}}\hspace{.2cm}\\
%     Department of Biostatistics, UNC, Chapel Hill\\
%     Naim Rashid \\
%     Department of Biostatistics, UNC, Chapel Hill \\
%     Joseph Ibrahim \\
%     Department of Biostatistics, UNC, Chapel Hill}
% 
%   \maketitle
% } \fi
% 
% \if0\blind
% {
%   \bigskip
%   \bigskip
%   \bigskip
%   \begin{center}
%     {\LARGE\bf Mixture Negative Binomial Expectation Maximization (NB-EM) Algorithm for Unsupervised Clustering}
% \end{center}
%   \medskip
% } \fi

%%%%%%%%%%%%%%%%%%%%%%%
%%%%% 0. ABSTRACT %%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
Clustering is a form of unsupervised learning that aims to uncover latent groups within data based on similarity across a set of features. A common application of this in biomedical research is in deriving novel cancer subtypes from patient gene expression data, given a set of informative genes. However, it is typically unknown a priori what genes may be informative in discriminating between clusters, and what the optimal number of clusters is. There is currently no methods that exist for unsupervised clustering of RNA-seq data that can simultaneously adjust for between-sample normalization factors and account for effects of potential confounding variables, while clustering patients and selecting cluster-discriminatory genes. To address this issue, we propose the Feature Selection and Clustering of RNAseq (FSCseq): a model-based clustering algorithm that utilizes a finite mixture of regression (FMR) model with a hybrid L2 and SCAD penalty. The maximization is done by coordinate-wise descent using the IRLS algorithm, allowing us to include normalization factors, and adjust for confounders in our modeling framework. Given the fitted model, our framework allows for subtype prediction in new patients via posterior probabilities of cluster membership. Based on simulations and real data, we show the utility of our method relative to competing approaches.
\end{abstract}

\begin{keywords}
clustering, genomics, EM, RNAseq, confounders
\end{keywords}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% 1. INTRODUCTION %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<setup, include=FALSE, cache=FALSE, echo=FALSE>>=
setwd("C:/Users/limdd/Documents/Research/Sweave")
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
@

\section{Introduction}
\label{sec:intro}

%MICROARRAY V RNASEQ%
RNA-seq is a recent platform for gene expression data based upon high-throughput sequencing. It has been shown to overcome some of the biases and limitations that are inherent in working with microarray, giving less background noise and providing a greater dynamic range for detection \citep{Hrdlickova2016}. Furthermore, studies have shown a strong correlation of results based on RNA-seq and microarray data, suggesting the reproducibility of the utilities of microarray analyses in RNA-seq.

%CLUSTERING METHODS MICROARRAY%
One area of key interest in cancer genomics is in clustering samples based on subject-specific gene expression profiles. This can provide valuable insight into possible relatedness of cancer samples by grouping similarly expressed samples together. Based on this relatedness, one may be able to make inferences on samples' subtypes of cancer. Subtype discovery has become a field of significant interest because studies have shown that the subtype of a patient's tumor not only affects the prognosis of the disease, but also the effectiveness of commonly-used treatments like chemotherapy \citep{Mao2017}. Being able to identify the subtype of cancer samples based on gene expression may potentially unlock the door to targeted therapy regimes, in which employed treatments can be more specific to the biology of the particular subtype, and thus more efficient and effective.

While there are numerous methods that have been developed to cluster microarray gene expression data \citep{Monti2003,Cho2008}, few are able to cluster RNA-seq gene expression. Due to the discrete nature of RNA-seq, the standard Gaussian model cannot be assumed of the underlying distribution, as can be done on microarray by methods like \textit{mclust} \citep{Scrucca2016}. Some current methods get around this by approximating RNA-seq with the normal distribution using some type of transformation \citep{Zwiener2014}. These transformations typically make the data 'more normal' to utilize existing methods for microarray, but there is not one transformation that is superior \citep{Noel-MacDonnell2018}. Thus, analyses using transformed count data would be dependent on the type of transformation used, which raises the question of reproducibility. Also, the few methods that have been developed for clustering raw RNA-seq data have been designed specifically to cluster genes rather than samples \citep{Si2013}.

%POINTS TO ADDRESS IN RNASEQ (normalization,count data,variable selection/prefiltering)%
Biases and artifacts inherent in RNA-seq data also need to be accounted for during clustering. Sequencing depth is a source of technical variation that describes the dependence of a gene's quantification on its length, for a particular sample. This can alter expression profiles, causing significant findings to be confounded by differing sequencing depths across the sample space. The effect of sequencing depth is estimated and adjusted for using one of an array of normalization steps, although none have been shown to be uniformly superior \citep{Li2015}. Also, the high dimensionality of a genetic dataset necessitates a dimension reduction scheme that can pinpoint genes that may be most likely to be informative in clustering, as a majority of genes may be uninformative and vary due to noise. Thus, many methods use some criterion to pre-filter genes that are nondiscriminatory in nature. A widely-used method of pre-filtering is done by ranking and thresholding genes based on its median absolute deviation (MAD) \citep{Chung2008}. Noise and other forms of technical variation also intermingles with biological variation, confounding the effects of biological differences. There have been many discussions regarding the irreproducibility of microarray analyses due to noise and batch effects \citep{Scherer2009}, and numerous attempts have been made to account for each of these sources of technical variation in RNA-seq, especially in the single cell RNA-seq setting.

Dealing with count data requires different distributional assumptions for model-based (MB) methods. Because there are well-established MB methods available for continuous data, the easiest way to account for count RNA-seq data is by transforming the discrete data to be approximately normal, and then inputting the transformed data into existing Gaussian assumption frameworks, like \textit{mclust}. \textit{mclust} can be used after transformations like the log, variance stabilizing, or rlog transformations, as these help make count data become more approximately Gaussian. However, analyses on transformations of discrete data are not robust, as they are highly dependent on the type of transformation used, and estimated parameters from such data can lack interpretability.
iCluster+ is an integrative method that assumes a naive Poisson distribution on untransformed count data. This is used alongside a penalized likelihood scheme to perform clustering \citep{Mo2013}. We believe, however, that such a model also has its limitations, as it does not account for extra-Poisson variation. A very recent method (NBMB) includes a framework assuming the negative binomial distribution to account for this extra variation \citep{Li2018}, but it does not contain any mode for feature selection of genes that may be of interest, and estimating separate dispersion parameters per cluster runs the risk of overfitting.

There are also some non-model-based methods that have been shown to be efficacious with RNA-seq data, such as the average-linkage hierarchical clustering (HC) and K-medoids clustering (KM) methods \citep{Jaskowiak2018}. HC works by iteratively fusing the two closest clusters together, starting with $n$ clusters and going down in number of clusters. The closeness is determined by a distance matrix and a linkage scheme. Typically, a 1-spearman or 1-pearson correlation is most commonly used, and Jaskowiak proposes that the average-linkage scheme provides the best results with RNA-seq. K-med is very similar in procedure to the widely-known K-means algorithm, but rather than assigning the means as the centroids, K-med assigns datapoints as centroids (medoids). K-med works similarly to K-means by minimizing the distance between cluster members and their corresponding centroid, but is more robust and can better handle count data. Although these do not have a mode of variable selection, they may be useful in clustering nonetheless after some pre-filtering scheme.

%OUR APPROACH%
In this paper, we introduce FSCseq (Feature Selection and Clustering of RNA-seq), in which we propose a finite mixture Negative Binomial model, incorporating a combination of the ridge (L2) and SCAD penalties \citep{Fan2001}. We perform feature selection by applying this hybrid penalty on the difference in estimated cluster log2 mean expression, which simultaneously shrinks the estimates closer together while inducing sparsity on the differences in these estimates across clusters. The parameter estimation and clustering is done using an Expectation Maximization (EM) algorithm. The E step weights are passed into the maximization (M step) to allow for cluster-specific estimation, and these weights also provide a very intuitive interpretation as the posterior probabilities of samples being in any particular cluster.

Unlike any other method for RNAseq, we are able to directly offset by normalization factors to adjust for sequencing depth, as well as allow for adjustments for confounders like age or purity. The regression scheme used in conjunction with our model assumption allows for seamless integration of these corrections, which can highly affect clustering results.

There are four primary steps to our method. First, we pre-filter out genes with low variability using the MAD criterion to remove likely uninformative genes. Second, we select the optimal number of clusters in the Order Selection step. Third, we search over a grid of possible combinations of the penalty parameters, and select the optimal tuning parameters. Fourth, we output the results of FSCseq run on the optimal parameters.

The EM algorithm is known to converge to local maxima. We attenuate this risk by searching over many different random initializations of cluster labels. We also evaluate the Classification EM with Simulated Annealing (CEM), an alternate to the EM that has been shown to lower the risk of the EM being "stuck" at a local maximum \citep{Celeux1992}. We leave this as an option in our package.

In our model, we assume that each gene shares a common overdispersion parameter. However, it can be argued that a separate dispersion parameter per cluster may be more appropriate, depending on the data. We call these two schemes gene-specific vs. cluster-specific dispersion schemes, respectively. We set gene-specific dispersions as the default in our method, but we also evaluate the cluster-specific dispersions assumption, and leave it as an option in our package.

Finally, FSCseq provides a very intuitive way to seamlessly perform subtype prediction. By imposing the new samples on the fitted model, we are able to derive posterior probabilities of new subjects being in each cluster. 

%%%%%%%%%%%%%%%%%%%%%%
%%%%% 2. METHODS %%%%%
%%%%%%%%%%%%%%%%%%%%%%

\section{Methods}
\label{sec:meth}

The main goal of FSCseq is two-fold: to 1. determine discriminatory genes based on differential expression of RNA-seq data (Feature Selection), and 2. cluster subjects based on similar expression profiles of genes (Clustering). We believe that our method is novel in that it provides a scheme to (a) allow for correction for sources of technical variation like sequencing depth, (b) adjust for effects of well-known confounders in genomic data, like age or tumor purity, and (c) perform prediction on new subjects based on the fitted model.

%%% 2.1 Obj fx %%%
\subsection{Likelihood Model}
Raw RNA-seq is widely known to be overdispersed count data, so we assume the negative binomial distribution in our regression model. For $Y \sim\ NB(\mu,\phi)$, the probability mass function of $Y$ is given by the "NB2" model described by \citet{Hilbe2009}:
\begin{equation}
f(y;\mu,\phi) = \binom{y+\phi^{-1}-1}{\phi^{-1}-1} \left[\dfrac{1}{1+\phi\mu}\right]^{\frac{1}{\phi}}\left[\dfrac{\phi\mu}{1+\phi\mu}\right]^{y}
\end{equation}

Now, let $y_{ij}$ be the count of the $i$'th subject for the $j$'th gene, where $i=1,...,n$ and $j=1,...,g$. We model $Y$ by a mixture of $K$ negative binomial distributions, where $K$ represents the number of underlying clusters in the data. With the assumption that each gene is independent, the density of $Y$ can be written:
\begin{equation}
f(\mathbf{y};\boldsymbol{\mu},\boldsymbol{\phi}) = \prod_{i=1}^n \prod_{j=1}^g \sum_{k=1}^K \pi_k f_{jk}(y_{ij};\mu_{ijk},\boldsymbol{\gamma_j},\phi_j)
\end{equation}

where $\sum_{k=1}^K \pi_k = 1$ are the mixing proportions, $\mu_{ijk}$ is the mean expression of gene $j$ for sample $i$ in cluster $k$, $\phi_j$ is the overdispersion parameter of gene j, and $\boldsymbol{\gamma_j}=(\gamma_{1j}, ..., \gamma_{Pj})$ are the effects of the $P$ covariates. Additionally, by using the sample-specific normalization factors as offsets in our regression setting, we adjust for differences in sequencing depth across samples. This causes the parametrization of the mean to be sample-specific, with the link and variance functions given as follows:
\begin{align}
log_2(\mu_{ijk}) = & \eta_{ijk} \beta_{jk} + \sum_{p=1}^{P} x_{ip}\gamma_{jp} + s_i \\
V(\mu_{ijk}) = & \mu_{ijk} + \phi_j\mu_{ijk}^2
\end{align}

where $\beta_{jk}$ represents the cluster log base 2 (log2) mean for gene $j$ and cluster $k$, and $s_i$ is the log2 of the subject-specific normalization factors calculated by DESeq2 \citep{Love2014}. We pass these normalization factors here as offsets into our regression model to correct for sequencing depth. Note that the equation parametrizes one common overdispersion parameter across clusters per gene. An alternative parametrization calls for separate cluster-specific dispersions, which replaces $\phi_j$ with $\phi_{jk}$ above. It is not known which scheme is more appropriate for dispersions in real data. Many prominent methods of analyzing gene expression like DESeq2 use gene-specific dispersion parameters to account for extra-Poisson variation. It can be argued that in cases where the differences in dispersion between clusters is very large, estimating additional cluster-specific dispersion parameters may be required to better fit the model. However, this may lead to overfitting and skew the clustering results. In this paper, we find that one common dispersion per gene tends to be more accurate in terms of performance, but we include the option to use distinct cluster-specific dispersions per gene as well.

% 2.1.1 Penalty
\subsubsection{Penalty}
The penalty we incorporate is a modified version of the grouped truncated lasso penalty, which uses a hybrid of the lasso (L1) and ridge (L2) penalties \citep{Pan2013}. Instead of the lasso, we utilize the Smoothly Clipped Absolute Deviation (SCAD) penalty, which is shown to introduce less bias than the classic L1 penalty, while still thresholding coefficients to zero. We balance between the two penalties using an additional parameter $\alpha$. We impose this penalty on the differences between log2 cluster means (denoted by $\theta$). For a given fixed gene $j$:
\begin{equation}
p_{\lambda,\alpha}(\boldsymbol{\beta_k})=\frac{\lambda(1-\alpha)}{2}\sum_{k<l} \norm{\beta_k-\beta_l-\theta_{kl}}_2^2 + \lambda\alpha \sum_{k<l}SCAD(\norm{\theta_{kl}}_2)
\end{equation}

where $\theta_{kl}=\beta_k-\beta_l$ is a parameter incorporated to allow for an efficient coordinate-wise descent maximization procedure. $SCAD(\theta)$ is the SCAD penalty on $\theta$, whose form is most widely given by its first derivative: $SCAD'(\theta)=\lambda^*\{I(\theta \leq \lambda^*)+[(a\lambda^*-\theta)_+/(a\lambda^*-\lambda^*)] I(\theta>\lambda^*)\}$ for $a>2$, $\theta>0$, and $\lambda^*=\lambda\alpha$. In this scheme, $\lambda$ controls the amount of penalization introduced into the model, and $\alpha$ parameter balances between the L2 and SCAD penalties, so that $\alpha=0$ corresponds to the L2 penalty, and $\alpha=1$ corresponds to the SCAD penalty. With this penalty, the log2 means can never be set exactly equal; however, the $\theta_{kl}$ parameter would be thresholded to zero when the log mean of cluster $k$ and $l$ are sufficiently close, indicating that the respective gene is nondiscriminatory across these two clusters. When the difference between clusters is thresholded to zero, the cluster log2 mean across these clusters are forced to be equal by taking their weighted average (weighted by sample size per cluster).

%%% 2.2 Computation %%%
\subsection{Computation}

Estimation of $\beta_{jk}$ and $\phi_j$ is done by maximizing the Q function, which is the conditional expectation of the complete data log-likelihood function (CDLL). The CDLL is given by:
\begin{equation}
log[L(\Psi)]=\sum_{i=1}^{n} \sum_{k=1}^{K} z_{ik} \{log(\pi_k)+log[f_k(\boldsymbol{y_i}; \boldsymbol{\beta_k},\boldsymbol{\gamma},\boldsymbol{\phi})]\}+p_{\lambda,\alpha}(\boldsymbol{\beta_k})
\end{equation}

where $z_{ik}=I(z_i=k)$ denotes the indicator of subject $i$ being in cluster $k$ and $f_k(\boldsymbol{y_i}; \boldsymbol{\beta_k},\boldsymbol{\gamma},\boldsymbol{\phi})=\prod_{j=1}^{g} f_{jk}(y_{ij}; \beta_{jk},\gamma_j,\phi_j)$. The cluster proportions are given by $\pi_k$. Because $z_{ik}$ is unobservable, we estimate this quantity by the conditional expectation of $z_{ik}$ given the parameters estimated from the $m$th step. For simplicity of the model, we assume that the expression of each gene is uncorrelated to that of any other gene, which makes the estimation problem of the parameters separable. We can thus implement a gene-by-gene maximization procedure, which we outline in the M step section.

% 2.2.1 E Step
\subsubsection{E Step}
We calculate the conditional expectation of the $z_{ik}$ given the current estimates of the parameters. For brevity, we denote $\hat{z}_{ik}^{(m)} = E[z_{ik} \mid \mathbf{y}, \boldsymbol{\hat{\beta}^{(m)}}, \boldsymbol{\hat{\gamma}^{(m)}}, \boldsymbol{\hat{\pi}^{(m)}}]$. Another way to think about this quantity is as the posterior probability of subject $i$ being in cluster $k$. These quantities are passed through as weights in the estimation of the coefficients in the subsequent M step. The $m$'th iteration of the E step update on these weights are given as follows:
\begin{equation}
\hat{z}_{ik}^{(m)}=\dfrac{\hat{\pi}_k^{(m)}f_k(\boldsymbol{y_i};\boldsymbol{\hat{\beta}_k^{(m)},\boldsymbol{\hat{\gamma}^{(m)}},\hat{\phi}^{(m)}})}{\sum_{l=1}^{K}\hat{\pi}_l^{(m)}f_l(\boldsymbol{y_i};\boldsymbol{\hat{\beta}_l^{(m)},\boldsymbol{\hat{\gamma}^{(m)}},\hat{\phi}^{(m)}})}
\end{equation}

At convergence, we are able to assign patients to clusters according to these posterior probabilities. These probabilities will also allow for partial cluster membership, as their values will be between $0$ and $1$. The cluster label of a subject is assigned to correspond to the cluster that yields the maximum posterior probability for that subject.

The EM algorithm is known to converge to the local maximum or saddle point rather than the global maximum. To prevent this, we compare many short-run initializations with our EM. Then, we choose the optimal initialization based on the BIC, and perform a long-run of the EM. This is similar to the "EM-em" strategy proposed by \cite{Biernacki2003}. We also assess the CEM, which incorporates a classification E step with simulated annealing. In general, we found that the convergence of the CEM took much longer than the classic EM, and was not feasible to select across many initializations in higher dimensions. Additionally, this scheme (without searching multiple initializations) did not consistently attain the global maximum, and thus also worked best in conjunction with a search on multiple random initializations. We also found that performance via CEM was highly dependent on the dimensionality of the data, due to the nontrivial problem of determining an optimal annealing rate and initial temperature for simulated annealing. Thus, we suggest using the classic EM with multiple random initialization searches over CEM in FSCseq; however, we leave the CEM as an alternative in our package.

% 2.2.2 M Step
\subsubsection{M Step}
In the M step of the EM algorithm, we update the current estimates of the parameters to maximize the penalized objective function. The maximization of $\pi_k$ and ($\beta_{jk}$, $\gamma_j$, $\phi_j$) are separable, thus they can be done independently.

%Est of beta
Maximization of the estimates of the cluster log means and dispersion parameters is performed by iteratively reweighted least squares (IRLS) using a coordinate descent algorithm. We first maximize the penalized objective function to estimate the cluster means. This is accomplished by using a transformed response that is reweighted across iterations of IRLS \citep{Breheny2011}. For fixed gene $j$, we transform the responses by the following equation:
$$\tilde{y}_{ik}=\hat{\eta_{ik}}+(\frac{y_i-g(\hat{\eta_{ik}})}{g'(\hat{\eta_{ik}})})$$

where $g()$ is the inverse link function for the Negative Binomial family with log2 link, thus $g(\eta)=\mu$, where $g^{-1}(\mu)=log_2(\mu)$ is the log2 link function.

Using this transformation, the penalized objective function becomes:
\begin{equation}
Q_j(\boldsymbol{\beta}) \approx \frac{1}{2n}(\mathbf{\tilde{y}}-\mathbf{X}\boldsymbol{\beta})'\mathbf{W}(\mathbf{\tilde{y}}-\mathbf{X}\boldsymbol{\beta})+\sum_{k=1}^{K}p_{\lambda,\alpha}(\beta_{jk})
\end{equation}

where \textbf{X} is a matrix of dimensions $(nK)$x$(K+P)$. The first $K$ columns consist of 1's and 0's that represent the indicator of each cluster for each transformed response, and the last $P$ columns represent the matrix of covariate values for each sample, repeated $K$ times to correspond to each transformed response. $\boldsymbol{\beta}$ is the vector of length $(K+P)$ corresponding to the $K$ cluster log2 means and $P$ covariates: $\boldsymbol{\beta}=(\beta_1,...,\beta_K,\gamma_1,...,\gamma_P)^T$. \textbf{W} is a $nK$x$nK$ diagonal matrix of the E step weights to correspond to each element of the transformed response; that is, we pass on $\hat{z}^{(m)}_{ik}$ as the weights in regressing $\tilde{y}_{ik}$ on X.

Therefore, we have $w_{ik}=\sqrt{\dfrac{\hat{z}^{(m)}_{ik} g'(\eta_{ik})^2}{V(\mu_{ik})}}$, where the variance is $V(\mu)=\mu + \phi\mu^2$ for the Negative Binomial. Assuming gene-by-gene independence, Equation 8 is maximized separately for each value of $j=1,...,g$. The update equations of cluster log2 baselines $\beta_1,...,\beta_K$and thresholding parameter $\theta$ become:
\begin{equation}
\begin{split}
\hat{\beta}_k^{(m+1)}&=\dfrac{\frac{1}{n_k}\sum_{i=1}^{nK}w_{ik}x_{ik}r_{ik}+\lambda(1-\alpha)[\sum_{l>k}(\hat{\beta}_l^{(m)}+\hat{\theta}_{kl}^{(m)})+\sum_{l<k}(\hat{\beta}_l^{(m+1)}-\hat{\theta}_{lk}^{(m)})]}{\lambda(1-\alpha)(K-1)+\frac{1}{n_k}\sum_{i=1}^{nK}w_{ik}x_{ik}^2} \\
r_{ik} &= \tilde{y}_{i}-\sum_{c \neq k}^{K}x_{ic}\beta_{c}-\sum_{p=1}^{P}x_{ip}\gamma_p\\
\hat{\theta}_{kl}^{(m+1)}&=\begin{dcases} 
      sgn(\hat{\theta}_{kl}^{(m)})(\norm{\hat{\theta}_{kl}^{(m)}}-\frac{\alpha}{1-\alpha})_+ & , \norm{\hat{\theta}_{kl}^{(m)}} \leq \lambda^* \\
      sgn(\omega)(\norm{\omega}-\frac{a\frac{\alpha}{1-\alpha}}{a-1-\frac{1}{\lambda(1-\alpha)}})_+ & , \lambda^* < \norm{\hat{\theta}_{kl}^{(m)}} \leq a\lambda\alpha\\
      \hat{\theta}_{kl}^{(m)} & , \norm{\hat{\theta}_{kl}^{(m)}} > a\lambda\alpha
   \end{dcases}\\
   \omega &= \frac{(a-1)\hat{\theta}_{kl}^{(m)}}{a-1-\frac{1}{\lambda(1-\alpha)}}\\
   \lambda^* &= \dfrac{\alpha}{1-\alpha}+\lambda\alpha
\end{split}
\end{equation}

We sequentially estimate the overdispersion parameter $\phi_j$, the covariate effects $\gamma_{j1}, ..., \gamma_{jP}$ and then each of the cluster log2 means $\beta_{j1}, ..., \beta_{jK}$. We update $\phi$ by maximum likelihood (ML) estimation, including a very small penalty (order of $10^{-25}$) to stabilize the estimate in the low sample size setting. We repeat the above procedure until convergence, and then repeat for each gene $j=1, ..., g$.

The form of the update does not allow $\alpha=1$, so the penalty parameter search should be restricted to $0\leq\alpha<1$.

In our analysis, we also compare the effects of fitting cluster-specific dispersion parameters versus one gene-specific dispersion parameter. In this case, we update the cluster dispersion parameters sequentially after estimating each respective log2 baseline coefficient.

% Convergence
The stopping criterion for the EM algorithm is based on a threshold on the Q function. The algorithm is considered to have "converged" if $\lvert Q^{(m+1)}-Q^{(m)} \rvert< \epsilon_1$. The stopping criterion for estimation in IRLS in the M step is based on the sum of squares of the parameters. The covariate effects, cluster log2 means, and dispersion parameters are considered to have converged if the absolute change across one iteration of all parameters is below $\epsilon_2$. We set $\epsilon_1 = 10^{-12}$ and $\epsilon_2 = 10^{-6}$.

% 2.2.3 Tuning Parameters
\subsubsection{Tuning Parameters}

The optimal number of clusters K is found by searching over a range of values and comparing the fit using the yielded BIC values. \ref{fig:1} gives a graphical representation of the procedure on an example simulated dataset

\begin{figure}
\begin{center}
%\includegraphics{C:/Users/limdd/Documents/Research/Sweave/Project1/BICvOrder.png}
<<echo=FALSE,fig=TRUE>>=
load("C:/Users/limdd/Documents/Research/Sweave/Project1/list_BIC_n100_g865_K3.Rout")
plot(list_BIC,ylab="BIC",xlab="K",main="Plot of BIC vs. order")
@
\end{center}
\caption{Order selection is done by choosing the order (K) that minimizes the BIC. Here, the true order is K = 3 in a simulated dataset of n = 100 and g = 835 (after pre-filtering low count genes), and 20 \% discriminatory genes with log2 fold change of 2.}
\label{fig:1}
\end{figure}

Optimal tuning parameters for $\lambda$ and $\alpha$ are also found by using the BIC criterion. Using the optimal order selected from the Order selection step, the algorithm searches over a grid of penalty values, and selects the combination that yields the lowest BIC. It may be nontrivial to determine an appropriate range of penalty parameter values to search. We recommend a tuning parameter search range of $\alpha = (0.00, 0.50)$ and $\lambda = (0.05, 1.00)$, with expansion of the search grid if the optimal values reach the endpoints.

\subsubsection{Prediction}
FSCseq is unique in its ability to easily and seamlessly perform prediction on new samples based on a fitted model. The E step weights $\hat{z}^{(m)}_{ik}$ have the nice interpretability as the posterior probability (PP) of subject $i$ being in cluster $k$. The cluster log2 means and dispersion parameters are estimated on the full dataset, or the training set. These estimates can be used to assess the expression profiles of added samples, analogous to the test set. By fitting the estimates on the new subjects, we can derive the PPs of each new sample, and draw inferences on them based on these probabilities. In a cancer setting, this type of prediction can be especially useful for predicting the subtype of a new sample based on its gene expression profile. If the subtypes of the training set are known a priori, matching the most probable cluster of the new sample with the cluster label in the training set will give the most probable subtype of the new sample.

However, correcting for sequencing depth in the prediction set is nontrivial. The normalization factors are specific to the samples in the training set. In order to adjust samples in the test set for sequencing depth, one can either re-estimate the factors based on the concatenation of the test and training data or estimate the factors using just the test set. The former can introduce bias, as the fitted values are calculated based on different normalization factors. The latter would often suffer due to small sample size in the test set compared to the training set. We leave this issue as beyond the scope of this paper, and show the utility of our prediction framework in simulations given the correct size factors.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% 3. Numerical Examples %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Numerical Examples}
\label{sec:examples}

%%% 3.1 Simulations %%%
\subsection{Simulations}

We simulated 25 datasets per condition, and spanned an extensive set of conditions. Variable conditions included log2 fold change ($LFC$), number of clusters ($K$), sample size ($n$), and the proportion of discriminatory genes ($p_{disc}$) in the dataset. We found that in simulations, the number of genes did not have a big effect on performance, so we fixed the number to 2000 genes ($g=2000$). We ran 24 simulations for each combination of conditions: $LFC=(1, 2)$, $K=(2, 4, 6)$, and $n=(100, 200)$, $p_{disc}=(0.05,0.10)$. We also simulated differences in sequencing depth by taking the size factors estimated from the TCGA Breast Cancer dataset, and incorporating them in our simulations. We then pass them into the FSCseq algorithm as offsets in the IRLS maximization scheme.

To explore the behaviors in various realistic settings, we simulated low and high baseline log2 mean expressions and low, moderate, moderately high, and very high noise values based on the initial estimates of expression and dispersion on the TCGA Breast Cancer dataset. These values were $\beta=(5,10)$ and $\phi=(0.15,0.35,0.50,1.00)$, respectively.

It is well-known that a majority of the genes in a typical dataset is nondiscriminatory across subtypes. In order to cluster subtypes accurately, it is important to filter out genes that are obviously nondiscriminatory in nature. One common way to do this is by filtering out genes whose median absolute deviation is low. We utilize this, along with the penalized scheme of our method to perform pre-filtering and variable selection on the dataset.

To assess its performance, we imposed MAD pre-filtering on all simulated datasets, keeping just the features with the top 20\% MAD scores. We applied FSCseq on each dataset and assessed the performance statistics under varying levels of baseline expression and noise, and across all combinations of variables ($LFC$, $K$, $n_k$). We measured clustering accuracy by the Adjusted Rand Index (ARI), which measures the agreement of derived clusters with the simulated clusters. We measured the feature selection performance by sensitivity (sens), or the proportion of discriminatory genes that were correctly determined to be discriminatory, and false positive rate (FPR), or the proportion of nondiscriminatory genes that were incorrectly determined to be discriminatory. We also analyzed the prediction portion of our algorithm by simulating a new dataset with the same number of features and simulated parameters, but with a smaller sample size $n_{pred}=20$. We show the full results below.

We searched a range of $K=1,...,7$ in our order selection step, and searched over a grid of $\lambda=(0.05,...,1.00)$ and $\alpha=(0,0.05,...,0.5)$ in our penalty parameter search step.

<<xtable1234, results=tex, echo=FALSE>>==
library(xtable)
#load("C:/Users/limdd/Documents/Research/Simulations/gene_fixed_mad25_icluster_and_pred/second/sim_res_tab1.RData")
#load("C:/Users/limdd/Documents/Research/Simulations/filtmad20/sim_res.RData")
#load("C:/Users/limdd/Documents/Research/Simulations/elasticSCAD/24sims/sim_res.RData")
load("C:/Users/limdd/Documents/Research/Simulations/log2_rescaled/sim_res.RData")

table1[,9] = table1[,9]*2000       # number of disc genes g_{disc}
#head(table1)
colnames(table1) = c("$\\beta$","$\\phi$","LFC","n","K","$K_{FSC}$","$OA_{FSC}$","$p_{disc}$","$g_{disc}$","$ARI_{FSC}$","sens","FPR","$sens_{pre}$","$FPR_{pre}$","PARI","$K_{iCl}$","$OA_{iCl}$","$ARI_{iCl}$","$K_{HC}$","$OA_{HC}$","$ARI_{HC}$","$K_{KM}$","$OA_{KM}$","$ARI_{KM}$","$K_{NBMB}$","$OA_{NBMB}$","$ARI_{NBMB}$","$K_{lMC}$","$OA_{lMC}$","$ARI_{lMC}$","$K_{vMC}$","$OA_{vMC}$","$ARI_{vMC}$","$K_{rMC}$","$OA_{rMC}$","$ARI_{rMC}$")

col_IDs=c(1,5,3,8,4,6:7,9:13,15)

table1_EM_15=table1[c(1:24,97:120),col_IDs]
table1_EM_35=table1[c(25:48,121:144),col_IDs]
table1_EM_50=table1[c(49:72,145:168),col_IDs]
table1_EM_100=table1[c(73:96,169:192),col_IDs]

place_NAs=function(tbl,cols){
  for(c in cols){
    unique_vals = tbl[,c][!duplicated(tbl[,c])]
    dupe_size = which(!duplicated(tbl[,c]))[2]-which(!duplicated(tbl[,c]))[1]
    
    obj=unique_vals[1]
    for(i in 1:length(unique_vals)){
      obj=c(obj,rep(NA,dupe_size-1))
      if(i<length(unique_vals)){obj=c(obj,unique_vals[i+1])}
    }
    
    tbl[,c]=obj
  }
  return(tbl)
}

table1_EM_15=place_NAs(table1_EM_15,1:5)
table1_EM_35=place_NAs(table1_EM_35,1:5)
table1_EM_50=place_NAs(table1_EM_50,1:5)
table1_EM_100=place_NAs(table1_EM_100,1:5)

table2 = table1[table1[,"$p_{disc}$"]==0.05,]

table2_other_order_15=place_NAs(table2[c(1:12,49:60),c(1,5,3,4,6,16,19,22,25,28,31,34)],1:4)
table2_other_order_35=place_NAs(table2[c(13:24,61:72),c(1,5,3,4,6,16,19,22,25,28,31,34)],1:4)
table2_other_order_50=place_NAs(table2[c(25:36,73:84),c(1,5,3,4,6,16,19,22,25,28,31,34)],1:4)
table2_other_order_100=place_NAs(table2[c(37:48,85:96),c(1,5,3,4,6,16,19,22,25,28,31,34)],1:4)

table2_other_OA_15=place_NAs(table2[c(1:12,49:60),c(1,5,3,4,7,17,20,23,26,29,32,35)],1:4)
table2_other_OA_35=place_NAs(table2[c(13:24,61:72),c(1,5,3,4,7,17,20,23,26,29,32,35)],1:4)
table2_other_OA_50=place_NAs(table2[c(25:36,73:84),c(1,5,3,4,7,17,20,23,26,29,32,35)],1:4)
table2_other_OA_100=place_NAs(table2[c(37:48,85:96),c(1,5,3,4,7,17,20,23,26,29,32,35)],1:4)

table2_other_ARI_15=place_NAs(table2[c(1:12,49:60),c(1,5,3,4,10,18,21,24,27,30,33,36)],1:4)
table2_other_ARI_35=place_NAs(table2[c(13:24,61:72),c(1,5,3,4,10,18,21,24,27,30,33,36)],1:4)
table2_other_ARI_50=place_NAs(table2[c(25:36,73:84),c(1,5,3,4,10,18,21,24,27,30,33,36)],1:4)
table2_other_ARI_100=place_NAs(table2[c(37:48,85:96),c(1,5,3,4,10,18,21,24,27,30,33,36)],1:4)

table2=table1[table1$K==2,]
table4=table1[table1$K==4,]
table_high_phi = table1[table1[,2]>=0.5,]
table2_high_phi = table_high_phi[table_high_phi$K==2,]
table4_high_phi = table_high_phi[table_high_phi$K==4,]

@


\begin{figure}
\begin{center}
<<echo=FALSE,fig=TRUE,height=4.8,width=8>>=
x1=table1$'$sens_{pre}$'[table1[,2]==0.15 & table1$K==2]
x2=table1$'$sens_{pre}$'[table1[,2]==0.35 & table1$K==2]
x3=table1$'$sens_{pre}$'[table1[,2]==0.50 & table1$K==2]
x4=table1$'$sens_{pre}$'[table1[,2]==1.00 & table1$K==2]

colors = 1:5

select = c(2,3,5,9)

plot(x=c(0.15,0.35,0.5,1),y=c(x1[1],x2[1],x3[1],x4[1]),type='b',col=colors[1],xlab=expression(phi),ylab="Sensitivity",
     ylim=c(.25,1),main=expression(paste("Plot of Sensitivity vs. ", phi," of Top 20% MAD Pre-filtering of Genes")))
for(i in 1:length(select)){
  points(x=c(0.15,0.35,0.5,1),y=c(x1[select[i]],x2[select[i]],x3[select[i]],x4[select[i]]),type='b',col=colors[i+1])
}
legend("bottomleft",col=1:5,legend=c("base","n=200",expression(paste(p[disc],"=0.1")),"LFC=2",expression(paste(beta,"=10"))),lty=1)
@
\end{center}
\caption{Plot of MAD pre-filtering sensitivity of discovering discriminatory genes vs noise at $K=2$. Base case (base, in black) is $\beta=5.00$, $n=100$, $p_{disc}=0.05$, $LFC=1$.
}
\label{fig:2}
\end{figure}

Figure \ref{fig:2} shows the effect on sensitivity of discovering disciminatory genes when varying one simulation parameter, keeping all else fixed. Each line represents a change of just one parameter from the base case, keeping all of the other parameters fixed as in the base case. We found that in correctly determining genes to be discriminatory, the increase in LFC from 1 to 2 yields the most dramatic improvement of the parameter shifts, followed by an increase in sample size from 100 to 200 ($n_k=50$ to $n_k=100$). We hypothesize that because $n_k=50$ is already a sufficiently large sample size, the increase in sample size does not have as dramatic of an improvement. The performance of MAD pre-filtering did not seem to be greatly affected by the magnitude of baseline expression $\beta$ or the proportion of discriminatory genes $p_{disc}$. $p_{disc}$ does not affect sensitivity because although pre-filtering would select more true discriminatory genes, sensitivity scales this down by an increased number of actually discriminatory genes.

We note that at very high noise ($\phi=1.00$), the MAD pre-filtering step already loses a significant number of discriminatory genes. This is especially problematic because many methods use MAD pre-filtering to filter out genes even before applying a clustering algorithm, and may lose valuable information on truly discriminatory genes in the presence of increased noise.

<<xtable1, results=tex, echo=FALSE>>=
rws <- rep(c(1:4),times=2)+rep(c(4,12),each=4)-1
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

tab1_obj=table1[rep(c(25:28,49:52),each=2)+rep(c(0,96),times=8),c("$\\beta$","$\\phi$","n","$p_{disc}$","$K_{FSC}$","$OA_{FSC}$","$ARI_{FSC}$","PARI")]
tab1_obj=tab1_obj[,c(2,4,3,1,5:8)]
tab1_obj=place_NAs(tab1_obj,1:3)

tab1=xtable(tab1_obj,
            digits=c(0,2,2,0,0,3,3,3,3),
            table.placement="!h",
            caption="Effect of increasing n: better order accuracy and ARI",
            label = "tab:1",na.print="")
print(tab1,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))
@

Table \ref{tab:1} shows results of clustering with FSCseq under $K=2, LFC=1$. We notice that as $n$ or $p_{disc}$ increase, order accuracy (OA) and ARI increase. As sample size increases, we have more information from more subjects to correctly cluster them. As the proportion of discriminatory genes increases, there are more genes to help FSCseq identify changes across samples in each respective cluster, also allowing cluster accuracy to increase. Even in a high noise setting, FSCseq performs very well, given sufficient sample size and a sufficient number of genes to guide the clustering along. Equivalent analyses on lower simulated noise showed perfect clustering performance, and can be found in the Supplementary Materials.

<<xtable2, results=tex, echo=FALSE>>=
rws <- rep(c(1:4),times=2)+rep(c(4,12),each=4)-1
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

table_FS = table1[rep(c(25:28,49:52),each=2)+rep(c(0,96),times=8),c("$\\beta$","$\\phi$","n","$p_{disc}$","sens","$sens_{pre}$","FPR")]
tab2_obj = table_FS[,c(2,4,3,1,5:7)]

tab2_obj = place_NAs(tab2_obj,1:3)

tab2=xtable(tab2_obj,
            digits=c(0,2,2,0,0,3,3,3),
            table.placement="!h",
            caption="Sensitivity generally improves as n or $\\beta$ increases, and worsen when $\\phi$ increases. Increase in $p_{disc}$ improves gene discovery performance at lower sample size, but performance saturates at high enough sample size. There is a trade-off between sensitivity and false positive rate (FPR) of gene discovery. At high noise and low sample size, order was selected at K=1, causing no gene selection",
            label = "tab:2",na.print="")
print(tab2,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))
@


Table \ref{tab:2} shows results of gene discovery with FSCseq under $K=2, LFC=1$, with varying $n$ $\beta$, $\phi$, and $p_{disc}$. Often, clustering algorithms suffer from low count genes because small technical variations can greatly influence the expression levels. Given the same LFCs, we find that FSCseq is able to correctly distinguish discriminatory genes at a higher rate when the baseline is larger or if the amount of technical variation (or simulated noise) is smaller. Also, an increase in sample size greatly increases the clustering performance, but also boosts the gene discovery performance as well.

Additionally, under unfavorable simulated conditions, there was a trade-off between sensitivity and FPR. Improving conditions (like increasing $n$ or $p_{disc}$) yielded higher sensitivity in gene discovery, but also slightly increased the rate of false discoveries. Still, even at very high simulated noise, the FPR never exceeded $0.16$. Moreover, when conditions already allowed for very high sensitivity in gene discovery, improving conditions caused false positive rates to decrease. In our simulations, we observed that in the trade-off between sensitivity and FPR, FSCseq puts priority on improving sensitivity, capping the FPR at a modest level. Once sensitivity is "saturated", i.e. the conditions allow the algorithm to correctly select most of the discriminatory genes, FSCseq then yields improved FPR under more favorably simulated conditions. Also, the sensitivity of gene discovery via FSCseq often reached the limit of the MAD pre-filtering sensitivity threshold. In other words, FSCseq often correctly identified all discriminatory genes that were allowed through the pre-filtering step, and was limited in performance only by the performance of the pre-filtering step.

We also compare with six competing methods: iCluster+ (iCl), average-linkage hierarchical clustering (HC), K-medoids (K-med), and mclust on log, variance stabilizing, and rlog transformations of the normalized data (lMC, vMC, rMC). Order selection for HC was done by using the NbClust package \citep{Charrad2014}, which compares thirty different techniques of order selection for agglomerative/K-means clustering methods. The optimal order was selected based on which value was selected most often by these methods. Order selection for K-medoids was done by selecting the order which maximizes the silhouette value. In this procedure, $K=1$ was excluded because it is not possible to derive a silhouette value with just one cluster.

Order selection for iCluster+ was difficult to automatize. The iCluster+ paper and manual suggest looking graphically for a plateau of the deviance ratio (\% Variability Explained) as the the optimal number of clusters. Mo elaborates in the manual of the iClusterPlus package that for increased noise in the dataset, the deviance ratio will continue to increase with higher order. We observed this pattern even at very low levels of noise, causing the highest deviance ratio to almost always be at the highest number of clusters. Thus, in order to systemize the procedure across numerous simulation cases, we selected an arbitrary threshold such that if the percent increase in variability explained is less that 0.05 with an added cluster, the increase in order is deemed insignificant, and the order is selected as the immediately previous value. This is ad hoc at best, but we could not find a better way to automate the order selection process with iCluster+ for numerous datasets. Qualitative determinations of order based on graphs of the deviance ratio are not only inefficient, but also unreliable and irreproducible. $K=1$ was also excluded from the search with iCluster+, since the function does not allow for analysis when there is not at least two distinct clusters.

Order selection of NBMB and the transformed mclust runs were done by the method built-in to the \textit{NB.MClust} and \textit{mclust} packages.

<<xtable3, results=tex, echo=FALSE>>=

tab3_K_obj = table1[c(17:20),c("$p_{disc}$","n","$K_{FSC}$","$K_{iCl}$","$K_{HC}$","$K_{KM}$","$K_{NBMB}$","$K_{lMC}$","$K_{vMC}$","$K_{rMC}$")]
tab3_ARI_obj = table1[c(17:20),c("$p_{disc}$","n","$ARI_{FSC}$","$ARI_{iCl}$","$ARI_{HC}$","$ARI_{KM}$","$ARI_{NBMB}$","$ARI_{lMC}$","$ARI_{vMC}$","$ARI_{rMC}$")]

colnames(tab3_K_obj)=c("$p_{disc}$","n","FSC","iCl","HC","KM","NBMB","lMC","vMC","rMC")
colnames(tab3_ARI_obj)=c("$p_{disc}$","n","FSC","iCl","HC","KM","NBMB","lMC","vMC","rMC")

tab3_obj = rbind(tab3_K_obj,tab3_ARI_obj)[c(1,5,2,6,3,7,4,8),]
tab3_obj = cbind(tab3_obj,c(rep(c("K","ARI"),nrow(tab3_obj)/2)))[,c(1:2,11,3:10)]

colnames(tab3_obj)[3] = ""
tab3_obj=place_NAs(tab3_obj,1:2)


rws <- c(2,3,6,7)
col <- rep("\\rowcolor[gray]{0.95}", length(rws))


tab3 = xtable(tab3_obj,
            digits=c(0,2,0,0,3,3,3,3,3,3,3,3),
            table.placement="!h",
            caption="Select examples of order selected by iCluster+ (iCl), hierarchical clustering (HC), K-medoids (KM), NB.MClust (NBMB), and mclust performed on log, variance-stabilizing, and rlog transformations (lMC, vMC, and rMC, respectively). Note: iCl, KM, and NBMB did not have an option to search K=1. Select examples of clustering performance by competing methods. At this high level of noise, iCl, HC, and KM on average significantly underselected $K=2$. Overall, out of the transformed mclust runs, lMC seems to perform best. FSCseq outperforms all other methods across the board.",
            label = "tab:3",na.print="")
print(tab3,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col)
      )

@


Tables \ref{tab:3} and shows the orders and ARIs found by competing methods, under select conditions: $\beta=5.00, \phi=0.15, K=6, LFC=1$. In each case, FSCseq seems to be superior in both approximating the correct order and in clustering performance. The order selection of iCluster+, HC, and KM proved very problematic, as all three consistently selected the lowest value of the order search grid. The transformed mclust runs performed much better, but we found that the performance was reliant on the type of transformation used, and thus the optimal transformation for these runs varied across simulation settings. The full table of comparisons between these methods across all simulation conditions can be found in the Supplementary Materials. Figure \ref{fig:bplots2} below show boxplots of ARI yielded by each method for one select simulation case.

\begin{figure} %%%%%% GOTTA RE RUN THIS %%%%%
\begin{center}
\includegraphics[width=170mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/select_sim_bplots_ARI.png}
\end{center}
\caption{"Boxplots of ARI at fixed case of $K=6$, $\beta=6.5$, $LFC=1$, $n=100$, and $p_{disc}=0.05$ of competing methods at low ($\phi=0.15$, top-left), moderate ($\phi=0.35$, top-right), moderately high ($\phi=0.50$, bottom-left), and very high ($\phi=1.00$, bottom-right) noise.}
\label{fig:bplots2}
\end{figure}

The clustering performance for FSCseq was better than all other competing methods, except in a few simulated datasets. In low and moderate noise, NBMB's performance seems to be variable. When there is very little noise, NBMB and mclust runs perform decently well. As simulated noise increases, performance decreases across all methods. At lower noise, the performance of mclust depends on the transformation. HC, KM, and iCl seem to perform very poorly at any level of noise. iCl performance spikes up at very high noise, perhaps suggesting that the poor clustering performance can be attributed to poor order selection caused by the arbitrarily thresholded automatized criterion.

%%% g vs cl, CEM vs EM %%%
Next, we introduce some variants of our method. For one, we have so far restricted the simulations to contain gene-specific dispersions. It is not currently known whether a scheme with one dispersion parameter across all clusters for each gene adequately portrays real data. It may sometimes be more appropriate to introduce cluster-specific dispersion parameters to better fit the data, yielding more accurate estimates. However, this may also result in overfitting the data, which would cause our model to get stuck at a local maxima. One potential drawback that may result is that the order may be underestimated, as the extra dispersion parameters may cause the algorithm to favor a smaller number of clusters in the data.

Secondly, prior work has shown that the EM algorithm tends to converge to the local maximum, rather than the global maximum. Thus, this may result in the algorithm being "stuck" at less than ideal conditions. One way to prevent this isto replace the current E step with the classification E step. This variant of the E step introduces some randomness by drawing the posterior probabilities closer together, causing the algorithm to overcome local maxima through small perturbations of the clustering index. We use a simulated annealing method to slowly wean off the noise-adding effects of the CEM, and revert to the original EM. \ref{tab:4} shows the results of these variants under simulated gene-specific and cluster-specific dispersions, respectively, as well as the analogous iCluster+ results. Results are based on 24 simulated datasets for each case.

<<xtable4,results=tex,echo=FALSE>>==
load("C:/Users/limdd/Documents/Research/Simulations/elasticSCAD/24sims_gvcl_EMvCEM/sim_res_gvcl_EMvCEM.RData")

tab4 = xtable(table2,
              digits=2,
              table.placement="!h",
              caption="Clustering, gene discovery, and prediction performance of EM/CEM on gene-specific/cluster-specific simulated dispersions. Comparisons done with competing methods based on the two dispersion schemes. Each row represents the average across 24 different simulated datasets with true order $K=3$, $n=100$, 2000 genes, and 5\\% discriminatory genes with log2 fold change of 1.",
              label = "tab:4",na.print=""
              #,floating.environment = "table*"
              )      # K=3, n=50, g=1000
print(tab4,include.rownames=T, sanitize.text.function=identity)

@

(1) gEM is the EM with gene-specific dispersions, as before; (2) gCEM is the CEM with gene-specific dispersions; (3) clEM is the EM with cluster-specific dispersions; and (4) clCEM is the CEM with cluster-specific dispersions.The first term refers to the scheme by which the data was simulated: "g" for simulated gene-specific dispersions, and "cl" for simulated cluster-specific dispersions.

We notice that the cluster-specific runs of both EM and CEM were not able to correctly determine the order. Due to the additional parameters, the model becomes overfitted and prefers fewer parameters in the model by favoring fewer clusters. iCluster+ again grossly overestimates the order, in part due to the inability to automatize a heuristic "elbow point" determination of order. HC and KM seem to underestimate the order significantly, as we've seen in the simulations, although simulating separate cluster-specific dispersions slightly increases this estimate. As far as clustering performance, the gEM and gCEM seems to outperform clEM and clCEM because of the misspecified order when allowing cluster-specific dispersions. However, we see that when the simulated dispersions were cluster-specific, the sensitivity and FPR of significant gene discovery were slightly improved by clEM and clCEM over gEM and gCEM.

In FSCseq, the EM option chooses to search over numerous initializations with short EM runs, then perform a full run with the EM based on the optimal initialization. The CEM option uses CEM instead of the EM for the initialization search and full run. Here, we see that the CEM seems to be performing slightly worse than the EM in clustering. Theoretically, however, the CEM may require fewer iterations, given an appropriate initial temperate and annealing rate, as it can help prevent the EM from being "stuck" at a local maximum. We found that the CEM's performance was highly dependent on the dimensionality of the data, so we set the initial temperature at $\tau=\sqrt{g}$ to allow for adaptation to the data, with an annealing rate of $\tau^{(m+1)}=0.9\tau^{(m)}$ \citep{Rose1998}.

% Batch effects adjustment comparison
Because of its fully regression-based scheme, FSCseq has the unique ability to adjust for potential covariates in the dataset. We simulated another 25 datasets with the same parameters as in the gene vs. cluster dispersion comparison, and simulated an additional batch effect equal to the simulated log2 fold change. We chose half of the samples at random to belong to batch A, and the rest to batch B. Samples in batch A were simulated as done previously, while samples in batch B were simulated with the additional batch effect. We selected half of the genes at random to apply said batch effect, thus preventing this effect from being corrected out by the normalization. Table \ref{tab:5} shows the results of FSCseq and competing methods.

<<xtable5,results=tex,echo=FALSE>>==
load("C:/Users/limdd/Documents/Research/Simulations/log2_rescaled/sim_res_comparison_phi35.RData")
#load("C:/Users/limdd/Documents/Research/Simulations/log2_rescaled/sim_res_comparison_phi50.RData") # shows bad performance for adjusted too

sim_res_adj=sim_res_adj_phi35
sim_res_unadj=sim_res_unadj_phi35

res_adj = c(sim_res_adj$K, sim_res_adj$ARI, sim_res_adj$disc, sim_res_adj$sens, sim_res_adj$falsepos, sim_res_adj$mean_pred_acc)
res_unadj = c(sim_res_unadj$K, sim_res_unadj$ARI, sim_res_unadj$disc, sim_res_unadj$sens, sim_res_unadj$falsepos, sim_res_unadj$mean_pred_acc)

K_others_adj = c(sim_res_adj$K_iClust, sim_res_adj$K_HC, sim_res_adj$K_KM, sim_res_adj$K_NBMB, sim_res_adj$K_log_MC, sim_res_adj$K_vsd_MC, sim_res_adj$K_rld_MC)
K_others_unadj = c(sim_res_unadj$K_iClust, sim_res_unadj$K_HC, sim_res_unadj$K_KM, sim_res_unadj$K_NBMB, sim_res_unadj$K_log_MC, sim_res_unadj$K_vsd_MC, sim_res_unadj$K_rld_MC)
ARI_others_adj = c(sim_res_adj$ARI_iClust, sim_res_adj$ARI_HC, sim_res_adj$ARI_KM, sim_res_adj$ARI_NBMB, sim_res_adj$ARI_log_MC, sim_res_adj$ARI_vsd_MC, sim_res_adj$ARI_rld_MC)
ARI_others_unadj = c(sim_res_unadj$ARI_iClust, sim_res_unadj$ARI_HC, sim_res_unadj$ARI_KM, sim_res_unadj$ARI_NBMB, sim_res_unadj$ARI_log_MC, sim_res_unadj$ARI_vsd_MC, sim_res_unadj$ARI_rld_MC)

K_others = (K_others_adj+K_others_unadj)/2
ARI_others = (ARI_others_adj+ARI_others_unadj)/2

tab_FSCseq_batch = cbind(res_adj,res_unadj)
tab_others_batch = cbind(K_others,ARI_others)

colnames(tab_FSCseq_batch) = c("FSCadj","FSCunadj")
rownames(tab_FSCseq_batch) = c("K","ARI","$p_{disc}$","sens","FPR","PARI")
colnames(tab_others_batch) = c("K","ARI")
rownames(tab_others_batch) = c("iCl","HC","KM","NBMB","lMC","vMC","rMC")

tab_others_batch = cbind(tab_others_batch,matrix(NA,ncol=4,nrow=7))

tab5_obj=cbind(tab_FSCseq_batch,t(tab_others_batch))

tab5 = xtable(tab5_obj,
              digits=3,
              table.placement="!h",
              caption="Results of FSCseq comparing adjusting vs. not adjusting for simulated batch effects.",
              label = "tab:5",na.print=""
              #,floating.environment = "table*"
              )      # K=3, n=50, g=1000
print(tab5,include.rownames=T, sanitize.text.function=identity)

@


%%% 3.2 Real Data %%%
\subsection{Real Data}
We performed comparisons of FSCseq (EM), iCluster+, HC, and KM in two real datasets: The Cancer Genome Atlas (TCGA) Breast Cancer (BRCA) and TCGA Bladder Cancer (BLCA). Datasets and annotations were obtained from the National Cancer Institute GDC Portal \citep{Grossman2016}. In both datasets, we first pre-filtered samples based on estimated tumor purity and incidence of each annotated subtype. We also pre-filtered genes based on low normalized (corrected for sequencing depth) count and MAD scores.

We compared each clustering method with the annotated subtypes with ARI. Also, we analyzed the clustering performance by performing survival analysis with the logrank test. This test typically uses a Chi-square statistic to measure significance, which assumes large sample size. A very recent study showed that this large sample approximation is not appropriate in many genomic settings, and proposed using an empirical p-value based on a permutation test in order to gauge significance \citep{Rappoport2018}. In fact, results of said study revealed that the Chi-square approximation logrank test always yields more significant results than the permutation-based test. We run the large-sample approximation logrank test, and attempted to incorporate the permutation-based logrank test, providing p-values to measure significant differences in survival across clusters. We found that when the number of survival events in one derived cluster is too few, the permutation-based method would fail, as the test would often randomly sample clusters with zero survival outcomes for all but one group. We assert that given more ideal circumstances in which more samples can be included, the empirical p-value is a more accurate metric of the significance of the difference in survival across groups.

\subsubsection{TCGA Breast Cancer Dataset}

We performed our clustering analysis on The Cancer Genome Atlas (TCGA) breast cancer (BRCA) dataset. This dataset contained 1215 subjects and 21022 genes. Subtyping was done by a previous study by analyzing the PAM50 genes, which have been heavily investigated as driving genes for breast cancer (Koboldt et al., 2012). Purity is known to be a very strong confounder for cancer genomic data. Thus, we narrowed down our analysis to only samples with estimated tumor purity greater than 0.9. We were left with 132 samples with 5 different subtypes: 53 luminal A, 38 luminal B, 32 basal-like, 6 HER2-enriched, and 2 normal-like. Due to the low incidence of the HER2-enriched and normal-like subtypes, we omitted these in our analysis. We performed our analysis on the remaining 124 samples with 3 distinct subtypes. Then, we filtered out genes with low count by excluding genes with MAD scores below the median MAD from our analysis, yielding 9062 total genes. We chose to be more liberal by selecting a higher threshold on the proportion of genes pre-selected via MAD (50\% rather than 20\% in our simulations) in order to help increase the sensitivity of keeping discriminatory genes in our analysis.

We performed clustering and feature selection on the resultant dataset of 123 samples and 4566 genes. Based on the results by Koboldt et al, we decided to expand the range of our order selection to $K=1, ..., 15$. We compared our clustering results with the subtypes that have been previously determined and annotated. These annotated subtypes are results based on the well-known PAM50 genes.

We also compared our method (EM) with iCluster+ (iCl), HC, KM, lMC, vMC, and rMC. Results are given in Table \ref{tab:BRCA}.

<<xtableBRCA,results=tex,echo=F>>=
load("C:/Users/limdd/Documents/Research/Real Data/TCGA BRCA/BRCA_mad50_pure0.9_3subtypes_compare_res.RData")

tab_BRCA= xtable(summary_table[,c(1,2,4,5,6)],
                 digits=c(0,0,rep(3,4)),
                 caption="ARI, average silhouette values (sil) and p-values from Log-Rank survival test with Chi-square approximation (LRpval) and with permutation-based empirical test (emppval), and the p-value of the Fisher's Exact test on the contingency table of survival events and cluster labels (fisherpval) of analyses performed on TCGA Breast Cancer dataset by FSCseq (EM) and competing methods compared to the annotated (anno).",
              label="tab:BRCA",
              #table.placement="H",
              na.print=""
              #,floating.environment = "table*"
              )
print(tab_BRCA,sanitize.text.function=identity)

@

FSCseq uncovered an order of $K=4$. iCluster+ drastically overestimated the order as $K=9$, while HC and KM both chose $K=2$. While the concordance was best for these two clustering results when compared to the annotations, we found that the cluster proportions were extremely skewed to one cluster, suggesting that the better agreement to the annotations was not necessarily indicative of greater similarity in clustering performance. The Fisher's Exact test yielded insignificant results across all methods. In fact, the permutation-based logrank test could not be performed in HC and KM due to these unbalanced cluster proportions, which yielded too few survival events in one group.

Compared to clusters from both iCl and NBMB, as well as to the annotated clusters, the FSCseq clusters yielded p-values that were significantly lower in both the Chi-square approximation and permutation-based logrank tests. lMC, vMC, and rMC performed better in terms of survival, with lMC and vMC yielding exactly the same clustering results. With the exception of NBMB, which greatly overestimated the number of clusters, Fisher's Exact test on vital status (vital) yielded the lowest p-value for the FSCseq clusters

Feature selection in FSCseq determined a total of 4283 genes to be discriminatory. \ref{fig:2} shows a heatmap of these genes, ordered by the derived clusters. Given the very small false positive rate in our simulations, we predict that many of these genes provide valuable information in differential expression across these clusters.

\begin{sidewaysfigure}
\includegraphics[width=250mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/BRCA_disc_HM.png}
\caption{Heatmap of derived discriminatory genes discovered by FSCseq on TCGA BRCA dataset. Cluster labels are annotated above, with derived clusters ("EM") and annotated clusters.}
\label{fig:2}
\end{sidewaysfigure}

Cluster 3 comprised mostly of Luminal A subtypes, with two Luminal B subtypes. Cluster 2 consisted of a mixture of Luminal A and Luminal B subtypes. The algorithm had a hard time distinguishing these two subtypes, suggesting strong similarities between the two subtypes. Cluster 1 contained all basal subtypes, mixed with two Luminal B subtypes. The basal subtype is the most distinct subtype of the three.

It has been widely known and accepted that the PAM50 genes are genes of significant interest in determining subtypes of cancer. We thus performed further analyses on just these PAM50 genes. Of note, the pre-filtering by MAD filtered out 7 of the PAM50 genes due to low counts or MAD values. Also, out of the 43 that made it past the pre-filtering step, our algorithm remarkably found 41 of them to be discriminatory across the derived clusters. This is important because the PAM50 genes were discovered by microarray platforms, and FSCseq is able to validate their significance via RNAseq. \ref{fig:3} shows the distribution of MAD scores of the PAM50 genes that were pre-filtered out, as well as the estimated log fold change across clusters for those PAM50 genes that were selected by our algorithm to be nondiscriminatory.

\begin{figure}
\begin{center}
\includegraphics[width=170mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/BRCA_MAD_LFC_PAM50.png}
\end{center}
\caption{(left) MAD scores of PAM50 genes, stratified by inclusion via MAD pre-filtering scheme; (right) Estimated LFC's of normalized counts across derived clusters}
\label{fig:3}
\end{figure}

The three PAM50 genes that were excluded by MAD pre-filtering were 'GRB7', 'MDM2', and 'ACTR3B', which yielded MAD values of $0.565$, $0.466$, and $0.464$ respectively. The median MAD value was $0.602$, so these genes were below the pre-filtering cut-off. Of the 47 PAM50 genes included in our analysis, the two genes that FSCseq found to be nondiscriminatory were 'ERBB2' and 'MMP11', which yielded estimated log2 fold changes of $0.346$ and $0.338$ across the derived clusters. Figure \ref{fig:4} is a heatmap of the 47 PAM50 genes that were included in our analysis. We see that the genes that FSCseq determined to be nondiscriminatory qualitatively do seem to be nondiscriminatory according to the heatmap.

\begin{figure}
\begin{center}
\includegraphics[width=180mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/BRCA_pam50_incl47_HM.png}
\end{center}
\caption{Heatmap of the 47 PAM50 genes included in analysis after pre-filtering, ordered by derived (EM) clusters. FSCseq variable selection determined genes 'ERBB2' and 'MMP11' to be nondiscriminatory}
\label{fig:4}
\end{figure}

\subsubsection{TCGA Bladder Cancer Dataset}

We also performed similar analyses on the TCGA Bladder Cancer dataset. This dataset contained 427 samples and 21022 genes, with annotated subtypes based on a study done by Robertson et al in 2017. Because of the smaller sample size (compared to the BRCA dataset), we included in our analysis samples whose estimated tumor purity was greater 0.8. This yielded 104 samples with 5 subtypes: 80 Luminal-papillary, 11 Neuronal, 8 Basal-squamous, 4 Luminal, and 1 Luminal-infiltrated. Due to the extremely low incidence of the Luminal and Luminal-infiltrated subtypes, we excluded them in our analysis, leaving us with 99 samples of 3 distinct subtypes. As before, we filtered just the genes with the top 50 quantile MAD scores, leaving 4141 genes in the analysis.

Robertson mentions the lower purity levels of the luminal-infiltrated and basal-squamous subtypes, and the higher purity levels of the luminal-papillary subtype. This was evident in our pre-filtering procedure, as 85 of the 86 annotated samples with luminal-infiltrated subtype and 139 out of 147 basal-squamous samples with basal-squamous subtype fell short of our purity threshold of 0.8, while 80 of the 144 annotated samples with luminal-papillary subtype had purity estimates greater than our threshold. See Table \ref{tab:BLCA}.

<<xtableBLCA,results=tex,echo=F>>=
load("C:/Users/limdd/Documents/Research/Real Data/TCGA BLCA/BLCA_mad50_pure0.8_3subtypes_compare_res.RData")

tab_BLCA = xtable(summary_table[,c(1,2,4,5,6)],
                  digits=c(0,0,rep(3,4)),
                  caption="ARI, average silhouette values (sil) and p-values from Log-Rank survival test with Chi-square approximation (LRpval) and with permutation-based empirical test (emppval), and the p-value of the Fisher's Exact test on the contingency table of survival events and cluster labels (fisherpval) of analyses performed on TCGA Bladder Cancer (BLCA) dataset by FSCseq (EM), iCluster+, HC, and KM.",
              label="tab:BLCA",
              #table.placement="H",
              na.print=""
              #,floating.environment = "table*"
              )
print(tab_BLCA,sanitize.text.function=identity)

@

% EDIT FROM HERE %
The FSCseq order selection step yielded $K=4$: one extra cluster than the annotated. This over-estimation of the order is due to the lower purity threshold on the BLCA samples, as compared to the BRCA samples. Regardless of the order misspecification, the Chi-square approximation logrank p-value of the EM clusters was $0.067$, which was significantly lower than the annotated clusters' p-value of $0.567$. iCluster+ overspecified the order further as $K=5$ and showed a logrank p-value of $0.126$, which was better than the annotations, but worse than FSCseq. The empirical p-value was able to be derived only in FSCseq and iCluster+ clusters, and FSCseq outperformed iCluster+. Although HC and KM both chose $K=2$ again, as in the BRCA dataset, the KM clusters actually yielded a smaller p-value than the annotated clusters. Also, although the HC yielded the highest average silhouette value, we found that the clustering was extremely uneven, with 96 samples in Cluster 1 and just three samples in Cluster 2. Additionally, the logrank test yielded the highest p-value for the HC clusters. This highlights the limitations of the silhouette value in groups with very small sample size, as the silhouette value will be highly variable and dependent on a few data points.

Our method determined a total of 3914 genes to be discriminatory. \ref{fig:5} shows a heatmap of these genes. 

\begin{sidewaysfigure}
\includegraphics[width=250mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/BLCA_disc_HM.png}
\caption{Heatmap of derived discriminatory genes discovered by FSCseq on TCGA BLCA dataset. Cluster labels are annotated above, with derived clusters ("EM") and annotated clusters.}
\label{fig:5}
\end{sidewaysfigure}

Gene enrichment analysis revealed ... % % \textbf{EDIT THIS SECTION} %
FSCseq was able to detect several genes that are known to be associated with bladder cancer, like FGFR3, RB1, and HRAS.

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% 4. DISCUSSION %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{sec:disc}

Our findings from the simulations and real data applications give evidence to the usefulness of our method. In our simulations, we found that the feature selection and clustering performance of FSCseq were extremely good and robust even at relatively high levels of noise. Analysis on the real data showed that clusters via FSCseq were more significant than the annotated clusters in survival. These annotations were typically done based on significant genes that were known a priori, as well as derived by integrative methods that drew information from other genomic datasets besides gene expression. Despite this, we showed that FSCseq is able to perform better using just raw RNAseq gene expression data. Moreover, of the 47 PAM50 genes included in analysis, FSCseq was able to correctly identify 45 of these genes as discriminatory. As these PAM50 genes were found to be significant driving genes via microarray platforms, this emphasizes the reproducibility and comparability of RNAseq to microarray. As RNAseq becomes more widely used, we posit that this platform can be used to improve upon known significant driving genes such as PAM50, and even to discover novel driving genes in the future.

One way by which this method can be drastically improved is by adjusting for tumor purity in the model. Because of the fluctuating tumor purity levels in real datasets, we were forced to filter out all but very high purity samples. In doing so, we lost a significant amount of information, especially in the case of the BLCA dataset, and we were often faced with low sample size issues. It was clear that the lower purity samples added more noise into the dataset; because of the higher noise in the BLCA dataset ($purity = 0.8$) compared to the BRCA dataset ($purity = 0.9$), FSCseq slightly overestimated the number of clusters in the BLCA dataset, whereas it correctly identified the order in the BRCA dataset. Ideally, a framework can be developed to seamlessly integrate estimated purity grades so we minimize the loss of information due to filtering.

Secondly, our regression-like framework allows us to easily adjust for confounders. This was beyond the scope of this paper, but adding covariates like age and gender may help improve our method by correcting for potential sources of confounding. This can be generalized further to adjust for batch effects, or potentially even purity levels.

Third, the MAD pre-filtering method we imposed on the features often showed significantly lower sensitivity at higher levels of noise in our simulations. This pre-filtering step is vital, as FSCseq is unable to deal with any discriminatory genes that are pre-filtered out and not included in the model. However, omitting the pre-filtering step can decrease order selection performance, as the proportion of discriminatory genes will be smaller and the model will prefer fewer clusters due to the large number of nondiscriminatory genes. A future direction can focus on refining the pre-filtering step, adjusting the MAD method to account for different levels of purity and other potential sources of noise. Otherwise, a goodness of fit statistic of an intercept-only model assuming some level of noise may be able to rank genes, like the MAD method we employ. We leave it as a future direction to further assess the pre-filtering step.

Fourth, currently we circumvent the widely-known issue of the EM algorithm converging to the local maximum (instead of the global maximum) by searching over many random initializations with short EM runs, then performing a final longer EM run with the optimal initialization selected by BIC. This is very computationally expensive, and can be improved to be more efficient. Rather than randomly sampling initializations, one can make a smaller number of more informed initializations based on existing clustering methods. Alternatively, one can perform clustering on different subsets of the entire feature space, and search over the resulting clusters.

Fifth, FSCseq is novel in its ability to assign posterior probabilities that can be used to assign future patients into existing clusters based on an already fitted model. However, this requires a way to adjust new samples' expression profiles for sequencing depth. A naive approach would be to re-estimate the size factors by concatenating the training and test datasets together. Otherwise, one can compare the expression profile of the new patient with the training set, and compute the new patient's size factor by using an average of the training set size factors weighted by similarity to each existing sample.

Lastly, we assume no gene-to-gene interaction in our model for simplicity. Allowing for correlation between genes may help improve performance, but would likely result in a much more computationally complex model. Although a finite mixture model is very computationally extensive, it may be worth introducing gene interaction depending on the degree of improvement in performance.

\backmatter
%  This section is optional.  Here is where you will want to cite
%  grants, people who helped with the paper, etc.  But keep it short!

\section*{Acknowledgements}

Special thanks to my co-advisors Dr. Naim Rashid and Dr. Joseph Ibrahim
This research was supported by NIH grant 5T32CA106209-13.\vspace*{-8pt}

%  If your paper refers to supplementary web material, then you MUST
%  include this section!!  See Instructions for Authors at the journal
%  website http://www.biometrics.tibs.org

\section*{Supplementary Materials}

<<xtableFSC, results=tex, echo=FALSE>>==

rws <- rep(c(1:4),times=6)+rep(c(4,12,20,28,36,44),each=4)-1
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

tab1 = xtable(table1_EM_15,
              digits=c(0,0,0,0,2,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with low noise ($\\phi = 0.15$) in simulated datasets on performance. Each row is based on 24 simulated datasets. Order Accuracy (OA) is the proportion of datasets that correctly selected the true K (order), and prediction accuracy (PA) is the proportion of new simulated subjects that were correctly clustered.",
              label = "tab:supp1",na.print="")      # K=3, n=50, g=1000
print(tab1,include.rownames=F, sanitize.text.function=identity,
              #floating.environment = "sidewaystable",
      add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{11pt}{12.5pt}\\selectfont")

tab2 = xtable(table1_EM_35,
              digits=c(0,0,0,0,2,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with moderate noise ($\\phi = 0.35$) in simulated datasets on performance.",
              label = "tab:supp2",na.print="")      # K=3, n=50, g=1000
print(tab2,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{11pt}{12.5pt}\\selectfont")

tab3 = xtable(table1_EM_50,
              digits=c(0,0,0,0,2,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with moderately high noise ($\\phi = 0.50$) in simulated datasets on performance.",
              label = "tab:supp3",na.print="")      # K=3, n=50, g=1000
print(tab3,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{11pt}{12.5pt}\\selectfont")

tab4 = xtable(table1_EM_100,
              digits=c(0,0,0,0,2,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with very high noise ($\\phi = 1.00$) in simulated datasets on performance.",
              label = "tab:supp4",na.print="")      # K=3, n=50, g=1000
print(tab4,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{11pt}{12.5pt}\\selectfont")

@


<<xtableothers, results=tex, echo=FALSE>>=

rws <- rep(c(1:4),times=3)+rep(c(4,12,20),each=4)-1
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

# ORDER

tab5 = xtable(table2_other_order_15,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with low noise ($\\phi = 0.15$) in simulated datasets on performance, compared to competing methods iCluster+, average-linkage hierarchical clustering (HC) and K-medoids (KM). Fixed $p_{disc}$ = 0.05",
              label = "tab:supp5",na.print="")      # K=3, n=50, g=1000

print(tab5,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab6 = xtable(table2_other_order_35,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with moderate noise ($\\phi = 0.35$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp6",na.print="")      # K=3, n=50, g=1000

print(tab6,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab7 = xtable(table2_other_order_50,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with moderately high noise ($\\phi = 0.50$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp7",na.print="")      # K=3, n=50, g=1000

print(tab7,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab8 = xtable(table2_other_order_100,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with very high noise ($\\phi = 1.00$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp8",na.print="")      # K=3, n=50, g=1000

print(tab8,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))


# OA

tab9 = xtable(table2_other_OA_15,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with low noise ($\\phi = 0.15$) in simulated datasets on performance, compared to competing methods iCluster+, average-linkage hierarchical clustering (HC) and K-medoids (KM).",
              label = "tab:supp9",na.print="")      # K=3, n=50, g=1000

print(tab9,include.rownames=F,# floating.environment = "sidewaystable", # this doesn't seem to work
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{10pt}{10.5pt}\\selectfont")

tab10 = xtable(table2_other_OA_35,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with moderate noise ($\\phi = 0.35$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp10",na.print="")      # K=3, n=50, g=1000

print(tab10,include.rownames=F,# floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{10pt}{10.5pt}\\selectfont")

tab11 = xtable(table2_other_OA_50,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with moderately high noise ($\\phi = 0.50$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp11",na.print="")      # K=3, n=50, g=1000

print(tab11,include.rownames=F,# floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{10pt}{10.5pt}\\selectfont")

tab12 = xtable(table2_other_OA_100,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with very high noise ($\\phi = 1.00$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp12",na.print="")      # K=3, n=50, g=1000

print(tab12,include.rownames=F,# floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{10pt}{10.5pt}\\selectfont")


# ARI 

tab13 = xtable(table2_other_ARI_15,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with low noise ($\\phi = 0.15$) in simulated datasets on performance, compared to competing methods iCluster+, average-linkage hierarchical clustering (HC) and K-medoids (KM).",
              label = "tab:supp13",na.print="")      # K=3, n=50, g=1000

print(tab13,include.rownames=F,# floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{9pt}{10pt}\\selectfont")

tab14 = xtable(table2_other_ARI_35,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with moderate noise ($\\phi = 0.35$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp14",na.print="")      # K=3, n=50, g=1000

print(tab14,include.rownames=F,# floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{9pt}{10pt}\\selectfont")

tab15 = xtable(table2_other_ARI_50,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with moderately high noise ($\\phi = 0.50$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp15",na.print="")      # K=3, n=50, g=1000

print(tab15,include.rownames=F,# floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{9pt}{10pt}\\selectfont")

tab16 = xtable(table2_other_ARI_100,
              digits=c(0,0,0,0,0,rep(2,8)),
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 5$ and $10$) with very high noise ($\\phi = 1.00$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:supp16",na.print="")      # K=3, n=50, g=1000

print(tab16,include.rownames=F,# floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col),
      size="\\fontsize{9pt}{10pt}\\selectfont")

@

% Web Appendix A, referenced in Section~\ref{s:model}, is available with
% this paper at the Biometrics website on Wiley Online
% Library.\vspace*{-8pt}

\section{References}
%  Here, we create the bibliographic entries manually, following the
%  journal style.  If you use this method or use natbib, PLEASE PAY
%  CAREFUL ATTENTION TO THE BIBLIOGRAPHIC STYLE IN A RECENT ISSUE OF
%  THE JOURNAL AND FOLLOW IT!  Failure to follow stylistic conventions
%  just lengthens the time spend copyediting your paper and hence its
%  position in the publication queue should it be accepted.

%  We greatly prefer that you incorporate the references for your
%  article into the body of the article as we have done here 
%  (you can use natbib or not as you choose) than use BiBTeX,
%  so that your article is self-contained in one file.
%  If you do use BiBTeX, please use the .bst file that comes with 
%  the distribution.  In this case, replace the thebibliography
%  environment below by 

\bibliographystyle{biom}
\bibliography{Proj1}
%\bibliography{proj1bib}

% \appendix
%  To get the journal style of heading for an appendix, mimic the following.
% 
% \section{}
% \subsection{Title of appendix}
% 
% Put your short appendix here.  Remember, longer appendices are
% possible when presented as Supplementary Web Material.  Please 
% review and follow the journal policy for this material, available
% under Instructions for Authors at \texttt{http://www.biometrics.tibs.org}.

\label{lastpage}

\end{document}