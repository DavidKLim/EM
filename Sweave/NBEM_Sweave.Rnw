%  template.tex for Biometrics papers
%
%  This file provides a template for Biometrics authors.  Use this
%  template as the starting point for creating your manuscript document.
%  See the file biomsample.tex for an example of a full-blown manuscript.

%  ALWAYS USE THE referee OPTION WITH PAPERS SUBMITTED TO BIOMETRICS!!!
%  You can see what your paper would look like typeset by removing
%  the referee option.  Because the typeset version will be in two
%  columns, however, some of your equations may be too long. DO NOT
%  use the \longequation option discussed in the user guide!!!  This option
%  is reserved ONLY for equations that are impossible to split across 
%  multiple lines; e.g., a very wide matrix.  Instead, type your equations 
%  so that they stay in one column and are split across several lines, 
%  as are almost all equations in the journal.  Use a recent version of the
%  journal as a guide. 
%  
%\documentclass[12pt]{article}
\documentclass[useAMS,usenatbib,referee]{biom}
%documentclass[useAMS]{biom}
%
%  If your system does not have the AMS fonts version 2.0 installed, then
%  remove the useAMS option.
%
%  useAMS allows you to obtain upright Greek characters.
%  e.g. \umu, \upi etc.  See the section on "Upright Greek characters" in
%  this guide for further information.
%
%  If you are using AMS 2.0 fonts, bold math letters/symbols are available
%  at a larger range of sizes for NFSS release 1 and 2 (using \boldmath or
%  preferably \bmath).
% 
%  Other options are described in the user guide. Here are a few:
% 
%  -  If you use Patrick Daly's natbib  to cross-reference your 
%     bibliography entries, use the usenatbib option
%
%  -  If you use \includegraphics (graphicx package) for importing graphics
%     into your figures, use the usegraphicx option
% 
%  If you wish to typeset the paper in Times font (if you do not have the
%  PostScript Type 1 Computer Modern fonts you will need to do this to get
%  smoother fonts in a PDF file) then uncomment the next line
%  \usepackage{Times}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{xfrac}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{url} % not crucial - just used below for the URL
\usepackage{float}
\usepackage[T1]{fontenc}
\usepackage{colortbl}
\usepackage{rotating}

%\usepackage{biblatex}
%\usepackage{harvard}


%%%%%%%%%%%%%%%%%%%% MACROS %%%%%%%%%%%%%%%%%
\def\bSig\mathbf{\Sigma}
\newcommand{\VS}{V\&S}
\newcommand{\tr}{\mbox{tr}}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
%
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother

%  The rotating package allows you to have tables displayed in landscape
%  mode.  The rotating package is NOT included in this distribution, but
%  can be obtained from the CTAN archive.  USE OF LANDSCAPE TABLES IS
%  STRONGLY DISCOURAGED -- create landscape tables only as a last resort if
%  you see no other way to display the information.  If you do do this,
%  then you need the following command.

%\usepackage[figuresright]{rotating}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%  Here, place your title and author information.  Note that in
%  use of the \author command, you create your own footnotes.  Follow
%  the examples below in creating your author and affiliation information.
%  Also consult a recent issue of the journal for examples of formatting.

\title[NTS:NEED TO ADD TCGA BRCA AND BLCA IN BIBLIO]{Model-based Simultaneous Feature Selection and Clustering of Raw RNA-seq Data for Subtype Discovery}

%  Here are examples of different configurations of author/affiliation
%  displays.  According to the Biometrics style, in some instances,
%  the convention is to have superscript *, **, etc footnotes to indicate
%  which of multiple email addresses belong to which author.  In this case,
%  use the \email{ } command to produce the emails in the display.

%  In other cases, such as a single author or two authors from
%  different institutions, there should be no footnoting.  Here, use
%  the \emailx{ } command instead.

%  The examples below corrspond to almost every possible configuration
%  of authors and may be used as a guide.  For other configurations, consult
%  a recent issue of the the journal.

%  Single author -- USE \emailx{ } here so that no asterisk footnoting
%  for the email address will be produced.

%\author{John Author\emailx{email@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.}

%  Two authors from the same institution, with both emails -- use
%  \email{ } here to produce the asterisk footnoting for each email address

%\author{John Author$^{*}$\email{author@address.edu} and
%Kathy Authoress$^{**}$\email{email2@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.}

%  Exactly two authors from different institutions, with both emails
%  USE \emailx{ } here so that no asterisk footnoting for the email address
%  is produced.

% \author
% {John Author\emailx{author@address.edu} \\
% Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.
% \and
% Kathy Author\emailx{anotherauthor@address.edu} \\
% Department of Biostatistics, University of North Carolina at Chapel Hill,
% Chapel Hill, North Carolina, U.S.A.}

%  Three or more authors from same institution with all emails displayed
%  and footnoted using asterisks -- use \email{ }

\author{David Lim$^*$\email{deelim@ad.unc.edu},
Naim Rashid$^{**}$\email{naim@unc.edu}, and
Joseph Ibrahim$^{***}$\email{ibrahim@bios.unc.edu} \\
Department of Biostatistics, University of North Carolina, Chapel Hill, NC, USA}

%  Three or more authors from same institution with one corresponding email
%  displayed

%\author{John Author$^*$\email{author@address.edu}, 
%Jane Author, and Dick Author \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K}

%  Three or more authors, with at least two different institutions,
%  more than one email displayed 

%\author{John Author$^{1,*}$\email{author@address.edu}, 
%Kathy Author$^{2,**}$\email{anotherauthor@address.edu}, and 
%Wilma Flinstone$^{3,***}$\email{wilma@bedrock.edu} \\
%$^{1}$Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K \\
%$^{2}$Department of Biostatistics, University of North Carolina at 
%Chapel Hill, Chapel Hill, North Carolina, U.S.A. \\
%$^{3}$Department of Geology, University of Bedrock, Bedrock, Kansas, U.S.A.}

%  Three or more authors with at least two different institutions and only
%  one email displayed

%\author{John Author$^{1,*}$\email{author@address.edu}, 
%Wilma Flinstone$^{2}$, and Barney Rubble$^{2}$ \\
%$^{1}$Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K \\
%$^{2}$Department of Geology, University of Bedrock, Bedrock, Kansas, U.S.A.}

\begin{document}
\SweaveOpts{concordance=TRUE}

% \setlength{\paperheight}{11in}
% \setlength{\paperwidth}{8.5in}


% \date{{\it Received October} 2007. {\it Revised February} 2008.  {\it
% Accepted March} 2008.}

%  These options will count the number of pages and provide volume
%  and date information in the upper left hand corner of the top of the 
%  first page as in published papers.  The \pagerange command will only
%  work if you place the command \label{firstpage} near the beginning
%  of the document and \label{lastpage} at the end of the document, as we
%  have done in this template.

%  Again, putting a volume number and date is for your own amusement and
%  has no bearing on what actually happens to your paper!  

\pagerange{\pageref{firstpage}--\pageref{lastpage}} 
% \volume{64}
% \pubyear{2008}
% \artmonth{December}

%  The \doi command is where the DOI for your paper would be placed should it
%  be published.  Again, if you make one up and stick it here, it means 
%  nothing!

% \doi{10.1111/j.1541-0420.2005.00454.x}

%  This label and the label ``lastpage'' are used by the \pagerange
%  command above to give the page range for the article.  You may have 
%  to process the document twice to get this to match up with what you 
%  expect.  When using the referee option, this will not count the pages
%  with tables and figures.  

\label{firstpage}

%  put the summary for your paper here

%% BLINDING %%
% \if1\blind
% {
%   \title{\bf Mixture Negative Binomial Expectation Maximization (NB-EM) Algorithm for Unsupervised Clustering}
%   \author{David Lim\thanks{
%     The authors gratefully acknowledge \textit{please remember to list all relevant funding sources in the unblinded version}}\hspace{.2cm}\\
%     Department of Biostatistics, UNC, Chapel Hill\\
%     Naim Rashid \\
%     Department of Biostatistics, UNC, Chapel Hill \\
%     Joseph Ibrahim \\
%     Department of Biostatistics, UNC, Chapel Hill}
% 
%   \maketitle
% } \fi
% 
% \if0\blind
% {
%   \bigskip
%   \bigskip
%   \bigskip
%   \begin{center}
%     {\LARGE\bf Mixture Negative Binomial Expectation Maximization (NB-EM) Algorithm for Unsupervised Clustering}
% \end{center}
%   \medskip
% } \fi

%%%%%%%%%%%%%%%%%%%%%%%
%%%%% 0. ABSTRACT %%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
Clustering is a form of unsupervised learning that aims to uncover latent groups within data based on similarity across a set of features. A common application of this in biomedical research is in deriving novel cancer subtypes from patient gene expression data, given a set of informative genes. However, it is typically unknown a priori what genes may be informative in discriminating between clusters, and what the optimal number of clusters is. Few methods exist for unsupervised clustering of RNA-seq data that can simultaneously adjust for between-sample normalization factors, account for effects of potential confounding variables, and cluster patients while selecting cluster-discriminatory genes. To address this issue, we propose the Feature Selection and Clustering of RNAseq (FSCseq): a model-based clustering algorithm that utilizes a finite mixture of regression (FMR) model with a hybrid L2 and SCAD penalty. The maximization is done by coordinate-wise descent using the IRLS algorithm, allowing us to include normalization factors, and to potentially adjust for confounders in our modeling framework. Given the fitted model, our framework allows for subtype prediction in new patients via posterior probabilities of cluster membership. Based on simulations and real data, we show the utility of our method relative to competing approaches.
\end{abstract}

\begin{keywords}
clustering, genomics, EM, RNAseq
\end{keywords}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% 1. INTRODUCTION %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<setup, include=FALSE, cache=FALSE, echo=FALSE>>=
setwd("C:/Users/limdd/Documents/Research/Sweave")
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
@

\section{Introduction}
\label{sec:intro}

%MICROARRAY V RNASEQ%
RNA-seq is a recent platform for gene expression data based upon high-throughput sequencing. It has been shown to overcome some of the biases and limitations that are inherent in working with microarray \citep{Zhao2014}, and gives less background noise and provides a greater dynamic range for detection \citep{Hrdlickova2016}. Furthermore, there have been studies to show a strong correlation of results based on RNA-seq and microarray data, suggesting the reproducibility of the utilities of microarray analyses in RNA-seq \citep{Chen2017}.

%CLUSTERING METHODS MICROARRAY%
One area of key interest in cancer genomics is in clustering samples based on subject-specific gene expression profiles. This can provide valuable insight into possible relatedness of cancer samples by grouping similarly expressed samples together. Based on this relatedness, one may be able to make inferences on samples' subtypes of cancer. Subtype discovery has become a field of significant interest because studies have shown that the subtype of a patient's tumor not only affects the prognosis of the disease (Blows et al 2010, Koboldt et al 2012, Robertson et al 2017), but also the effectiveness of commonly-used treatments like chemotherapy \citep{Carey2011,Mao2017}. Being able to identify the subtype of cancer samples based on gene expression may potentially unlock the door to targeted therapy regimes, in which employed treatments can be more specific to the biology of the particular subtype, and thus more efficient and effective.

While there are numerous methods that have been developed to cluster microarray gene expression data \citep{Xie2007,Monti2003,Kluger2003,Cho2008}, few are able to cluster RNA-seq gene expression. Due to the discrete nature of RNA-seq, the standard Gaussian model cannot be assumed of the underlying distribution, as can be done on microarray by methods like mclust \citep{Yeung2001}. Some current methods get around this by approximating RNA-seq with the normal distribution using some type of transformation \citep{Zwiener2014}. These transformations typically make the data 'more normal' to utilize existing methods for microarray, but there is not one transformation that is superior \citep{Noel-MacDonnell2018}. Thus, analyses using transformed count data would be dependent on the type of transformation used, which raises the question of reproducibility. Also, the few methods that have been developed for clustering raw RNA-seq data have been designed specifically to cluster genes rather than samples \citep{Si2013}.

%POINTS TO ADDRESS IN RNASEQ (normalization,count data,variable selection/prefiltering)%
Biases and artifacts inherent in RNA-seq data also need to be accounted for during clustering. This is typically done using one of an array of normalization steps \citep{Li2015}, although none have been shown to be uniformly superior. Also, the high dimensionality of a genetic dataset necessitates a dimension reduction scheme that can pinpoint genes that may be most likely to be informative in clustering, as a majority of genes may be uninformative and vary due to noise. Thus, many methods use some criterion to pre-filter genes that are nondiscriminatory in nature \citep{Ritter2015}. A widely-used method of pre-filtering is done by ranking and thresholding genes based on its median absolute deviation (MAD) \citep{Chung2008} (\textbf{Alternatives to discuss?}). Noise and other forms of technical variation also intermingles with biological variation, confounding the effects of biological differences. There have been many discussions regarding the irreproducibility of microarray analyses due to noise and batch effects \citep{Scherer2009}, and many attempts have been made to account for these technical variations in RNA-seq, especially in the single cell RNA-seq setting \citep{Brennecke2013,Ding2015}. Sequencing depth is another form of technical variation that describes the dependence of a gene's quantification on its length \citep{Tarazona2011}. This can alter expression profiles dramatically, causing significant findings to be confounded by its sequencing depth.

Dealing with count data requires different distributional assumptions for model-based (MB) methods. Because there are well-established MB methods available for continuous data, the easiest way to account for count RNA-seq data is by transforming the discrete data to be approximately normal, and then inputting the transformed data into existing Gaussian assumption frameworks. One such framework that is widely used is called mclust \citep{Scrucca2016}. Mclust can be used after a log (logMC), variance stabilizing (vsdMC), or rlog (rldMC) transformation, as these transformations make count data becomes more approximately Gaussian. 
iCluster+ is an integrative method that assumes a naive Poisson distribution on untransformed count data. This is used alongside a penalized likelihood scheme to perform clustering \citep{Mo2013}. We believe, however, that such a model also has its limitations, as it does not account for extra-Poisson variation. A very recent method (NBMB) includes a framework assuming the negative binomial distribution to account for this extra variation \citep{Li2018}, but it does not contain any mode for feature selection of genes that may be of interest, and does not mitigate the possibility of overfitting.

There are also some non-model-based methods that have been shown to be efficacious with RNA-seq data, such as the average-linkage hierarchical clustering (HC) and K-medoids clustering (KM) methods \citep{Jaskowiak2018}. HC works by iteratively fusing the two closest clusters together, starting with $n$ clusters and going down in number of clusters. The closeness is determined by a distance matrix and a linkage scheme. Typically, a 1-spearman or 1-pearson correlation is most commonly used, and Jaskowiak proposes that the average-linkage scheme provides the best results with RNA-seq. K-med is very similar in procedure to the widely-known K-means algorithm, but rather than assigning the means as the centroids, K-med assigns datapoints as centroids (medoids). K-med works similarly to K-means by minimizing the distance between cluster members and their corresponding centroid, but is more robust and can better handle count data. Although these do not have a mode of variable selection, they may be useful in clustering nonetheless after some pre-filtering scheme.

%OUR APPROACH%
In this paper, we introduce FSCseq (Feature Selection and Clustering of RNA-seq), in which we propose a finite mixture Negative Binomial model, incorporating a combination of the L2 and SCAD penalties \citep{Fan2001}. By applying this hybrid penalty on the difference in estimated log means, we are able to shrink the cluster parameter estimates closer together, while selecting out genes whose difference in expression across clusters is sufficiently low. The adaptive nature of the SCAD penalty does not introduce as much bias as a classic L1 penalty, while maintaining the thresholding aspect of the lasso. The model is set in a regression scheme to allow for offsetting by normalization factors to adjust for sequencing, and to potentially allow for adjustments for confounders. The estimation is done using an Expectation Maximization (EM) algorithm. The E step weights are passed into the maximization (M step) to allow for cluster-specific estimation, and these weights also provide a very intuitive interpretation as the posterior probabilities of samples being in any particular cluster.

There are four primary steps to our method. First, we pre-filter out genes with low variability using the MAD criterion to remove likely uninformative genes. Second, we select the optimal number of clusters in the Order Selection step using the Bayesian Information Criterion (BIC). Third, we search over a grid of possible combinations of the penalty parameters, and select the optimal tuning parameters using the BIC. Fourth, we input the optimal order and parameters into a full run of our algorithm.

In this paper, we explore FSCseq EM, as well as an alternative E step update to potentially overcome the limitation of the classic EM of converging to a local maximum. Also, we attempt to assess whether one dispersion parameter per gene (gene-specific dispersions) or one parameter per cluster in each gene (cluster-specific dispersions) is more appropriate. Our framework allows for a separate fitted dispersion per cluster, but our findings reveal that a single parameter per gene may suffice and perhaps be more appropriate.

%%%%%%%%%%%%%%%%%%%%%%
%%%%% 2. METHODS %%%%%
%%%%%%%%%%%%%%%%%%%%%%

\section{Methods}
\label{sec:meth}

The main goal of our FSCseq is two-fold: 1. to determine discriminatory genes based on differential expression of RNA-seq data(Feature Selection), and 2. to cluster subjects based on similar expression profiles of genes (Clustering). We believe that our method is novel in that it provides a scheme to not only allow for correction for sources of technical variation like sequencing depth, but also to derive posterior probabilities of a sample's subtype based on the model that is fit on the dataset, which may be especially useful in prediction. We utilize an EM algorithm to maximize our likelihood model.

%%% 2.1 Obj fx %%%
\subsection{Likelihood Model}
Raw RNA-seq is count data, so we assume the negative binomial distribution in our regression model. For $Y \sim\ NB(\mu,\phi)$, the probability mass function of Y is given by the "NB2" model described by \citet{Hilbe2009}:
\begin{equation}
f(y;\mu,\phi) = \binom{y_i+\phi^{-1}-1}{\phi^{-1}-1} \left[\dfrac{1}{1+\phi\mu_i}\right]^{\frac{1}{\alpha}}\left[\dfrac{\phi\mu_i}{1+\phi\mu_i}\right]^{y_i}
\end{equation}

Now, let $y_{ij}$ be the count of the $i$'th subject for the $j$'th gene, where $i=1,...,n$ and $j=1,...,g$. We model Y by a mixture of K negative binomial distributions, where K represents the total number of underlying clusters in the data. With the assumption that each gene is independent, the density of Y can be written:
\begin{equation}
f(\mathbf{y};\boldsymbol{\mu},\boldsymbol{\phi}) = \prod_{i=1}^n \prod_{j=1}^g \sum_{k=1}^K \pi_k f_{jk}(y_{ij};\mu_{jk},\phi_j)
\end{equation}

where $\sum_{k=1}^K \pi_k = 1$ are the mixing proportions, $\mu_{jk}$ is the mean of cluster k in gene j, and $\phi_j$ is the dispersion parameter of gene j. The link and variance functions are given as follows:
\begin{align}
log_2(\mu_{ijk}) = & \beta_{jk} + s_i \\
V(y_{jk}) = & \mu_{jk} + \phi_j\mu_{jk}^2
\end{align}

where $\beta_{jk}$ represents the cluster log base 2 (log2) mean for gene j and cluster k, and $s_i$ is the log2 of the subject-specific normalization factors calculated by DESeq2 \citep{Love2014}. We pass these normalization factors here as offsets into our regression model to correct for sequencing depth. Note that the equation calls for one common dispersion parameter per gene. The analog that we will assess is the use of separate cluster-specific dispersions, which replaces $\phi_j$ with $\phi_{jk}$ above. It is not known which scheme is more appropriate for dispersions in real data. Many prominent methods of analyzing gene expression like DESeq2 use gene-specific dispersion parameters to account for extra-Poisson variation. However, it can be argued that in cases where the differences in dispersion between clusters is very large, estimating additional cluster-specific dispersion parameters may be required to better fit the model. However, this may lead to overfitting and skew the clustering results. In this paper, we find that one common dispersion per gene tends to be more accurate in terms of performance, but we will include the option to use distinct cluster-specific dispersions per gene as well.

% 2.1.1 Penalty
\subsubsection{Penalty}
The penalty we incorporate is a modified version of the grouped truncated lasso penalty, which uses a hybrid of the lasso (L1) and ridge (L2) penalties \citep{Pan2013}. Instead of the lasso, we utilize the Smoothly Clipped Absolute Deviation (SCAD) penalty, which is shown to introduce less bias than the classic L1 penalty, while still being able to threshold coefficients to zero. We incorporate this hybrid penalty by adding an additional parameter to balance between the two penalty terms, much like $\alpha$ in the elastic net penalty \citep{Zou2005}. In this context, rather than penalizing coefficients ($\beta$) to zero like in a typical regression setting, we penalize the differences between log2 cluster means (denoted by $\theta$) to zero.
\begin{equation}
p_{\lambda}(\beta)=\frac{\lambda(1-\alpha)}{2}\sum_{k<l} \norm{\beta_k-\beta_l-\theta_{kl}}_2^2 + \lambda\alpha \sum_{k<l}SCAD(\norm{\theta_{kl}}_2)
\end{equation}

where $\theta_{kl}=\beta_k-\beta_l$ is a reparametrization to store the difference between estimated cluster log means in the previous iteration, and $SCAD(\theta)=$ \textbf{Insert form of SCAD penalty here}. In this penalization scheme, $\lambda$ controls the amount of penalization introduced, and $\alpha$ parameter balances between the L2 and SCAD penalties. Under this penalty, the difference in log means can never be set exactly to zero. However, the $\theta_{kl}$ parameter would be thresholded to zero when the log mean of cluster $k$ and $l$ are sufficiently close, which would indicate that the respective gene is nondiscriminatory across these two clusters. When the difference between clusters is thresholded to zero, the cluster log2 mean across these clusters are forced to be equal by taking their weighted average (weighted by sample size per cluster).

The formulation controls between the L2 and SCAD penalties by the $\alpha$ parameter. A value of $\alpha=0$ corresponds to the L2 penalty, while a value of $\alpha=1$ corresponds to the SCAD penalty.

%%% 2.2 Computation %%%
\subsection{Computation}

Estimation of $\beta_{jk}$ and $\phi_j$ is done by maximizing the Q function, which is the conditional expectation of the complete data log-likelihood function (CDLL). The CDLL is given by:

\begin{equation}
log[L(\Psi)]=\sum_{i=1}^{n} \sum_{k=1}^{K} z_{ik} \{log(\pi_k)+log[f_k(\boldsymbol{y_i}; \boldsymbol{\beta_k},\boldsymbol{\phi})]\}+p_\lambda(\beta)
\end{equation}

where $z_{ik}=I(z_i=k)$ denotes the indicator of subject $i$ being in cluster $k$ and $f_k(\boldsymbol{y_i}; \boldsymbol{\beta_k})=\prod_{j=1}^{g} f_{jk}(y_{ij}; \beta_{jk},\phi_j)$. The cluster proportions are given by $\pi_k$. Because $z_{ik}$ is unobservable, we estimate this quantity by the conditional expectation of $z_{ik}$ given the parameters estimated from the $m$th step. For simplicity of the model, we assume that the expression of each gene is uncorrelated to that of any other gene, which makes the maximization of $\beta_{jk}$ and $\phi_j$ separable. We can then implement a gene-by-gene maximization procedure, which we outline in the M step section.

% 2.2.1 E Step
\subsubsection{E Step}
We calculate the conditional expectation of the $z_{ik}$ given the current estimates of the parameters. For brevity, we denote $\hat{z}_{ik}^{(m)} = E[z_{ik} \mid \mathbf{y}, \boldsymbol{\hat{\beta}^{(m)}}, \boldsymbol{\hat{\pi}^{(m)}}]$. Another way to think about this quantity is as the posterior probability of subject $i$ being in cluster $k$. These quantities are passed through as weights in the estimation of the coefficients in the maximization step. The $m$'th iteration of the E step update on these weights are given as follows:

\begin{equation}
\hat{z}_{ik}^{(m)}=\dfrac{\hat{\pi}_k^{(m)}f_k(\boldsymbol{y_i};\boldsymbol{\hat{\beta}_k^{(m)},\hat{\phi}_k^{(m)}})}{\sum_{l=1}^{K}\hat{\pi}_l^{(m)}f_l(\boldsymbol{y_i};\boldsymbol{\hat{\beta}_l^{(m)},\hat{\phi}_l^{(m)}})}
\end{equation}

At convergence, we are able to assign patients to clusters according to these posterior probabilities. These probabilities will also allow for partial cluster membership, as their values will be between 0 and 1. The actual cluster label is assigned to the cluster that corresponds to the maximum value of the posterior probabilities for that subject.

The EM algorithm is known to be able to converge to the local maximum or saddle point rather than the global maximum \citep{Yu2018}. To prevent this, we compare many short-run initializations with our EM. Then, we choose the optimal initialization based on the BIC, and perform a long-run of the EM. This is similar to the "EM-em" strategy proposed by \cite{Biernacki2003}.

\textbf{Not sure whether to include CEM}
Biernacki also assesses popular alternatives to this approach, incorporating the classification EM (CEM), but we found that the convergence of the CEM took much longer, and was not feasible to select across many initializations in higher dimensions. The CEM by itself (without searching multiple initializations) did not reliably attain the global maximum. We further attempted searching short-run initializations via EM, then using CEM in the final run. However, the CEM often knocked the good starting point back into a local maximum. Thus, we determined that a scheme with short EM runs with a final EM run yielded the best results in this setting. However, we leave the CEM as an alternative to the EM in our package.

% 2.2.2 M Step
\subsubsection{M Step}
In the M step of the EM algorithm, we update the current estimates of the parameters to maximize the penalized objective function. The maximization of $\pi_k$ and $\beta_{jk}$ are separable, thus they can be done independently.

%Est of beta
Maximization of the estimates of the cluster log means and dispersion parameters is performed by iteratively reweighted least squares using a coordinate descent algorithm. We first maximize the penalized objective function to estimate the cluster means. This is accomplished by using a transformed response \citep{Breheny2011}. We fix a gene $j$, and transform the responses by the following:

$$\tilde{y}_{ik}=\hat{\eta_k}+(\frac{y_i-g(\hat{\eta}_k)}{g'(\hat{\eta}_k)})$$

Here, $g()$ refers to the inverse link function for the Negative Binomial family with log link, thus $g(\eta)=\mu$, where $g^{-1}(\mu)=log(\mu)$ is the standard log link function.

Using this transformation, the penalized objective function becomes:

\begin{equation}
Q_j(\boldsymbol{\beta}) \approx \frac{1}{2n}(\mathbf{\tilde{y}}-\mathbf{X}\boldsymbol{\beta})'\mathbf{W}(\mathbf{\tilde{y}}-\mathbf{X}\boldsymbol{\beta})+\sum_{k=1}^{K}p_{\boldsymbol{\lambda}}(\beta_{jk})
\end{equation}

where X is an $(nK)$x$K$ matrix of 1's and 0's that represent the indicator of each cluster for each transformed response, and W is the matrix of the E step weights. In this framework, we pass on $\hat{z}^{(m)}_{ik}$ as the weights in regressing $\tilde{y}_{ik}$ on X.

Therefore, we have $w_{ik}=\sqrt{\dfrac{\hat{z}^{(m)}_{ik} g'(\eta)^2}{V(\mu)}}$, where the variance is $V(\mu)=\mu + \phi\mu^2$ for the Negative Binomial. Equation 3 is maximized for each value of $j=1,...,g$. The update equations become:

\begin{equation}
\begin{split}
\hat{\beta}_k^{(m+1)}&=\dfrac{\frac{1}{n}\sum_{i=1}^{n}w_{ik}\tilde{y}_{ik}+\lambda(1-\alpha)[\sum_{l>k}(\hat{\beta}_l^{(m)}+\hat{\theta}_{kl}^{(m)})+\sum_{l<k}(\hat{\beta}_l^{(m+1)}-\hat{\theta}_{lk}^{(m)})]}{\lambda(1-\alpha)(K-1)+\frac{1}{n}\sum_{i=1}^{n}w_{ik}} \\
\hat{\theta}_{kl}^{(m+1)}&=\begin{dcases} 
      sgn(\hat{\theta}_{kl}^{(m)})(\norm{\hat{\theta}_{kl}^{(m)}}-\frac{\alpha}{1-\alpha}) & , \norm{\hat{\theta}_{kl}^{(m)}} \leq \lambda\alpha \\
      \frac{(a-1)\hat{\theta}_{kl}^{(m)} - sgn(\hat{\theta}_{kl}^{(m)})a\frac{\alpha}{1-\alpha}}{a-1-\frac{1}{\lambda(1-\alpha)}} & , \lambda\alpha < \norm{\hat{\theta}_{kl}^{(m)}} \leq a\lambda\alpha \\
      \hat{\theta}_{kl}^{(m)} & , \norm{\hat{\theta}_{kl}^{(m)}} > a\lambda\alpha
   \end{dcases}
\end{split}
\end{equation}

The gene $j$ is fixed, and the above procedure is repeated for every gene $j=1, ..., g$. In this framework, $\hat{\theta}_{kl}^{(m)}$ represents the difference in estimated log means between cluster $k$ and $l$ at the $m$th iteration. After sequentially updating the cluster means, we estimate the overdispersion parameter $\phi$ using a maximum likelihood (ML) approach. However, this approach is limited due to instability when sample size is small. To mitigate this, we include a very small penalty (order of $10^{-50}$) on the ML estimation of $\phi$ to stabilize the estimate in the low sample setting.

At $\alpha=1$, the SCAD penalty will set all genes as nondiscriminatory. At $\alpha < 1$, the L2 penalty shrinks the log means closer together. The $\lambda$ parameter adjusts the amount of shrinkage introduced. \textbf{lambda doesn't affect selection (SCAD)?}

\textbf{Not sure if we do this: g vs cl}
We also compared the effects of fitting a common dispersion per gene, and cluster-specific dispersions per gene. It is not known which would be more appropriate for this type of data. Cluster-specific dispersion parameters may provide a better fitting model to the data, but gene-specific dispersion parameters will allow for more sparsity and avoid the issue of overfitting. The function in the R package will include the option to use either scheme.

% Convergence
The stopping criterion for the EM algorithm is based on a threshold on the Q function. The algorithm is considered to have "converged" if $\lvert Q^{(m+1)}-Q^{(m)} \rvert< \epsilon_1$

The stopping criterion for the IRLS in the M step is based on a threshold on the sum of squares of the parameters. The algorithm is considered to have converged if $\lvert \boldsymbol{\beta}^{(l+1)}-\boldsymbol{\beta}^{(l)} \rvert + \lvert \boldsymbol{\phi}^{(l+1)}-\boldsymbol{\phi}^{(l)} \rvert < \epsilon_2$

We set $\epsilon_1 = 10^{-12}$ and $\epsilon_2 = 10^{-6}$.

% 2.2.3 Tuning Parameters
\subsubsection{Tuning Parameters}

The optimal number of clusters K is found by searching over a range of values and comparing the fit using the yielded BIC values. \ref{fig:1} gives a graphical representation of the procedure on an example simulated dataset

\begin{figure}
\begin{center}
%\includegraphics{C:/Users/limdd/Documents/Research/Sweave/Project1/BICvOrder.png}
<<echo=FALSE,fig=TRUE>>=
load("C:/Users/limdd/Documents/Research/Sweave/Project1/list_BIC_n100_g865_K3.Rout")
plot(list_BIC,ylab="BIC",xlab="K",main="Plot of BIC vs. order")
@
\end{center}
\caption{Order selection is done by choosing the order (K) that minimizes the BIC. Here, the true order is K = 3 in a simulated dataset of n = 100 and g = 835 (after pre-filtering low count genes), and 20 \% discriminatory genes with log2 fold change of 2.}
\label{fig:1}
\end{figure}

Optimal tuning parameters for $\lambda$ and $\alpha$ are also found by using the BIC criterion. Using the optimal order selected from the Order selection step, the algorithm searches over a grid of penalty values, and selects the combination that yields the lowest BIC.

\subsubsection{Prediction}
Prediction is one of the most valuable utilities of our method. The E step weights $w_{ik}$ have the nice interpretability as the posterior probability (PP) of subject $i$ being in cluster $k$. The cluster log2 means and dispersion parameters are estimated on the full dataset, or the training set. These estimates can be used to assess the expression profiles of added samples, analogous to the test set. By fitting the estimates on the new subjects, we can derive the PPs of each new sample, and draw inferences on them based on these probabilities. In a cancer setting, this type of prediction can be especially useful for predicting the subtype of a new sample based on its gene expression profile. If the subtypes of the training set are known a priori, matching the most probable cluster of the new sample with the cluster label in the training set can give a good idea of the subtype of the new sample.

This framework is not without its drawbacks. For one, the corrections for sequencing depth per sample, or the size factors, are estimated on the training set. For an additional test case, it is not known how best to handle these size factors. These corrections are typically estimated based on the full data before any pre-filtering. Thus, we may lose some information if we simply re-estimate the size factors by concatenating the training and test sets. In the scope of this paper, we do not deal with this issue, but show the utility in simulations given the correct size factors.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% 3. Numerical Examples %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Numerical Examples}
\label{sec:examples}

%%% 3.1 Simulations %%%
\subsection{Simulations}

It is well-known that a majority of the genes in a typical dataset is nondiscriminatory across subtypes. In order to cluster subtypes accurately, it is important to filter out genes that are obviously nondiscriminatory in nature. One common way to do this is by filtering out genes whose median absolute deviation is low \citep{Chung2008}. We utilize this, along with a subsequent wrapper \citep{Ritter2015} in our method to perform pre-filtering and variable selection on the dataset.

We simulated 24 datasets per condition, and spanned an extensive set of conditions. Variable conditions included log fold change ($LFC$), number of clusters ($K$), sample size ($n$), and the proportion of discriminatory genes ($p_{disc}$) in the dataset. We found that in simulations, the number of genes did not have a big effect on performance, so we fixed the number to 2000 genes ($g=2000$). We ran 24 simulations for each combination of conditions: $LFC=(1, 1.5)$, $K=(2, 4, 6)$, and $n=(100, 200)$, $p_{disc}=(0.05,0.10)$. We also simulated differences in sequencing depth by taking the size factors estimated from the TCGA Breast Cancer dataset, and incorporating them in our simulations. We then pass them into the FSCseq algorithm as offsets in the IRLS maximization scheme.

To explore the behaviors in various realistic settings, we simulated low and high baseline log2 mean expressions and low, moderate, moderately high, and very high noise values based on the initial estimates of expression and dispersion on the TCGA Breast Cancer dataset. These values were $\beta=(3.75,6.5)$ and $\phi=(0.15,0.35,0.50,1.00)$, respectively.

We imposed pre-filtering on all simulated datasets, keeping just the features with the top 20\% of MAD scores. We applied FSCseq on each dataset and assessed the performance statistics under varying levels of baseline expression and noise, and across all combinations of variables ($LFC$, $K$, $n_k$). We measured clustering accuracy by the Adjusted Rand Index (ARI), which measures the agreement of derived clusters with the simulated clusters. We measured the feature selection performance by sensitivity (sens), or the proportion of discriminatory genes that were correctly determined to be discriminatory, and false positive rate (FPR), or the proportion of nondiscriminatory genes that were incorrectly determined to be discriminatory. We also analyzed the prediction portion of our algorithm by simulating a new dataset with the same number of features and simulated parameters, but with a smaller sample size $n_{pred}=\floor{0.1n}$. We show the full results in Tables \ref{tab:1} \ref{tab:2}.

We searched a range of $K=1,...,7$ in our order selection step, and searched over a grid of $\lambda=(0.1,0.25,0.5,...,3.5)$ and $\alpha=(0,0.05,...,0.5)$ in our penalty parameter search step.

<<xtable1234, results=tex, echo=FALSE>>==
library(xtable)
#load("C:/Users/limdd/Documents/Research/Simulations/gene_fixed_mad25_icluster_and_pred/second/sim_res_tab1.RData")
#load("C:/Users/limdd/Documents/Research/Simulations/filtmad20/sim_res.RData")
load("C:/Users/limdd/Documents/Research/Simulations/elasticSCAD/24sims/sim_res.RData")

#head(table1)
colnames(table1) = c("$\\beta$","$\\phi$","LFC","n","K","$K_{FSC}$","$OA_{FSC}$","$p_{disc}$","$\\hat{p}_{disc}$","$ARI_{FSC}$","sens","FPR","$sens_{pre}$","$FPR_{pre}$","PA","$K_{iCl}$","$OA_{iCl}$","$ARI_{iCl}$","$K_{HC}$","$OA_{HC}$","$ARI_{HC}$","$K_{KM}$","$OA_{KM}$","$ARI_{KM}$","$K_{NBMB}$","$OA_{NBMB}$","$ARI_{NBMB}$","$K_{lMC}$","$OA_{lMC}$","$ARI_{lMC}$","$K_{vMC}$","$OA_{vMC}$","$ARI_{vMC}$","$K_{rMC}$","$OA_{rMC}$","$ARI_{rMC}$")

table1_EM_15=table1[c(1:24,97:120),c(1:13,15)][,-2]
table1_EM_35=table1[c(25:48,121:144),c(1:13,15)][,-2]
table1_EM_50=table1[c(49:72,145:168),c(1:13,15)][,-2]
table1_EM_100=table1[c(73:96,169:192),c(1:13,15)][,-2]

table2 = table1[table1[,"$p_{disc}$"]==0.05,]

table2_other_order_15=table2[c(1:12,49:60),c(1:6,16,19,22,25,28,31,34)][,-2]
table2_other_order_35=table2[c(13:24,61:72),c(1:6,16,19,22,25,28,31,34)][,-2]
table2_other_order_50=table2[c(25:36,73:84),c(1:6,16,19,22,25,28,31,34)][,-2]
table2_other_order_100=table2[c(37:48,85:96),c(1:6,16,19,22,25,28,31,34)][,-2]

table2_other_OA_15=table2[c(1:12,49:60),c(1:5,7,17,20,23,26,29,32,35)][,-2]
table2_other_OA_35=table2[c(13:24,61:72),c(1:5,7,17,20,23,26,29,32,35)][,-2]
table2_other_OA_50=table2[c(25:36,73:84),c(1:5,7,17,20,23,26,29,32,35)][,-2]
table2_other_OA_100=table2[c(37:48,85:96),c(1:5,7,17,20,23,26,29,32,35)][,-2]

table2_other_ARI_15=table2[c(1:12,49:60),c(1:5,10,18,21,24,27,30,33,36)][,-2]
table2_other_ARI_35=table2[c(13:24,61:72),c(1:5,10,18,21,24,27,30,33,36)][,-2]
table2_other_ARI_50=table2[c(25:36,73:84),c(1:5,10,18,21,24,27,30,33,36)][,-2]
table2_other_ARI_100=table2[c(37:48,85:96),c(1:5,10,18,21,24,27,30,33,36)][,-2]

rws <- rep(c(1:4),times=6)+rep(c(4,12,20,28,36,44),each=4)-1
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

tab1 = xtable(table1_EM_15,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50 $) with low noise ($\\phi = 0.15$) in simulated datasets on performance. Each row is based on 24 simulated datasets. Order Accuracy (OA) is the proportion of datasets that correctly selected the true K (order), and prediction accuracy (PA) is the proportion of new simulated subjects that were correctly clustered.",
              label = "tab:1",na.print="")      # K=3, n=50, g=1000
print(tab1,include.rownames=F, sanitize.text.function=identity,
              #floating.environment = "sidewaystable",
      add.to.row=list(pos=as.list(rws),command=col))

tab2 = xtable(table1_EM_35,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with moderate noise ($\\phi = 0.35$) in simulated datasets on performance.",
              label = "tab:2",na.print="")      # K=3, n=50, g=1000
print(tab2,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab3 = xtable(table1_EM_50,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with moderately high noise ($\\phi = 0.50$) in simulated datasets on performance.",
              label = "tab:3",na.print="")      # K=3, n=50, g=1000
print(tab3,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab4 = xtable(table1_EM_100,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with very high noise ($\\phi = 1.00$) in simulated datasets on performance.",
              label = "tab:4",na.print="")      # K=3, n=50, g=1000
print(tab4,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

@

Under low to moderate noise (Table \ref{tab:1}) the order selection and clustering performance are perfect with FSCseq. In this low to moderate noise cases, the sensitivity of the gene discovery portion of FSCseq were exactly the same as that of the MAD pre-filtering method. This showed that FSCseq correctly uncovered discriminatory genes for every simulated feature included in the analysis, but was in fact limited by the MAD pre-filtering method. For example, at low baseline ($\beta=3.75$), moderate noise ($\phi=0.35$), and low log fold change ($LFC=1$) with $n_k=25$, we found that the MAD pre-filtering sensitivity (MADsens) was 0.8, which means we picked up on average of 80\% of the truly discriminatory genes under these conditions. The false positive rate (FPR) of the MAD pre-filtering is omitted here because we are forcing a threshold of 20\% on pre-filtered genes, thus the FPR would be misleading and, in fact, noninformative.

At higher levels of noise (Table \ref{tab:2}), we start to see the performance decline. When the amount of noise is equal to the log fold change, we see that the order is selected to be 1. Because the algorithm cannot distinguish between simulated significant differences in expression and simulated noise, the EM jumbles all of the samples into one cluster, causing terrible performance across all datasets. Keeping all else constant, we see that increasing the number of samples per cluster ($n_k$) or increasing the LFC increases the performance in both clustering (ARI) and feature selection sensitivity (sens).

One noteworthy pattern we observed was a very strong correlation between clustering performance (ARI) and order selection accuracy (OA). In fact, many results showed absolute concordance between ARI and OA that signified that FSCseq would cluster samples perfectly ($ARI=1$) if the correct order was determined in the order selection step, while clustering would obviously be less than ideal under incorrectly selected orders. Order selection is a very significant part of the unsupervised clustering problem, and our results indicate the vital nature of this step.

We also observed that the false positive rate was not greatly increased due to less ideal conditions (higher noise, lower LFC, smaller $n_k$, smaller $\beta$). Rather, the FPR seems to stay relatively constant at less than 0.03 across the board. FSCseq's ability to keep the FPR low across less than ideal simulated cases can allow researchers to save valuable time and resources in performing follow-up studies on genes that were falsely determined to be significant.

Finally, we note that the prediction accuracy was perfect ($PA=1$) across all conditions. Since prediction was performed only on datasets whose order was correctly selected, this again highlights the importance of the order selection step. But it is very exciting to see that even in cases with very high noise ($\phi=1$) and low LFC ($LFC=1$), given sufficient samples per cluster $n_k=50$, FSCseq is able to correctly predict every newly simulated sample. It is important to note, however, that the size factors were known a priori. In most real-life settings, we will not have that luxury. There is work to be done in real datasets to adjust for sequencing depth for each additional subject we attempt to perform prediction on.

We also compare with three competing methods: iCluster+, average-linkage hierarchical clustering (HC), and K-medoids (K-med). Order selection for HC was done by using the NbClust package \citep{Charrad2014}, which compares thirty different techniques of order selection for agglomerative/K-means clustering methods. The optimal order was selected based on which value was selected most often by these methods. Order selection for K-medoids was done by selecting the order which maximizes the silhouette value. In this procedure, $K=1$ was excluded because it is not possible to derive a silhouette value with just one cluster.

Order selection for iCluster+ was difficult to automatize. The iCluster+ paper and manual suggest looking graphically for a plateau of the deviance ratio (\% Variability Explained) as the the optimal number of clusters. Mo elaborates in the manual of the iClusterPlus package that for increased noise in the dataset, the deviance ratio will continue to increase with higher order. We observed this pattern even at very low levels of noise, causing the highest deviance ratio to almost always be at the highest number of clusters. Thus, in order to systemize the procedure across numerous simulation cases, we selected an arbitrary threshold such that if the percent increase in variability explained is less that 0.05 with an added cluster, the increase in order is deemed insignificant, and the order is selected as the immediately previous value. This is ad hoc at best, but we could not find a better way to automate the order selection process with iCluster+ for numerous datasets. Qualitative determinations of order based on graphs of the deviance ratio are not only inefficient, but also unreliable and irreproducible. $K=1$ was also excluded from the search with iCluster+, since the function does not allow for analysis when there is not at least two distinct clusters.

\ref{tab:3} and \ref{tab:4} show side-by-side comparisons of order selection and clustering performances for the FSCSeq, iCluster+, HC, and KM.

<<xtable5678, results=tex, echo=FALSE>>=

rws <- rep(c(1:4),times=3)+rep(c(4,12,20),each=4)-1
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

# ORDER

tab5 = xtable(table2_other_order_15,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with low noise ($\\phi = 0.15$) in simulated datasets on performance, compared to competing methods iCluster+, average-linkage hierarchical clustering (HC) and K-medoids (KM). Fixed $p_{disc}$ = 0.05",
              label = "tab:5",na.print="")      # K=3, n=50, g=1000

print(tab5,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab6 = xtable(table2_other_order_35,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with moderate noise ($\\phi = 0.35$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:6",na.print="")      # K=3, n=50, g=1000

print(tab6,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab7 = xtable(table2_other_order_50,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with moderately high noise ($\\phi = 0.50$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:7",na.print="")      # K=3, n=50, g=1000

print(tab7,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab8 = xtable(table2_other_order_100,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with very high noise ($\\phi = 1.00$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:8",na.print="")      # K=3, n=50, g=1000

print(tab8,include.rownames=F, sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))


# OA

tab5 = xtable(table2_other_OA_15,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with low noise ($\\phi = 0.15$) in simulated datasets on performance, compared to competing methods iCluster+, average-linkage hierarchical clustering (HC) and K-medoids (KM).",
              label = "tab:9",na.print="")      # K=3, n=50, g=1000

print(tab5,include.rownames=F, floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab6 = xtable(table2_other_OA_35,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with moderate noise ($\\phi = 0.35$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:10",na.print="")      # K=3, n=50, g=1000

print(tab6,include.rownames=F, floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab7 = xtable(table2_other_OA_50,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with moderately high noise ($\\phi = 0.50$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:11",na.print="")      # K=3, n=50, g=1000

print(tab7,include.rownames=F, floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab8 = xtable(table2_other_OA_100,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with very high noise ($\\phi = 1.00$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:12",na.print="")      # K=3, n=50, g=1000

print(tab8,include.rownames=F, floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))


# ARI 

tab5 = xtable(table2_other_ARI_15,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with low noise ($\\phi = 0.15$) in simulated datasets on performance, compared to competing methods iCluster+, average-linkage hierarchical clustering (HC) and K-medoids (KM).",
              label = "tab:13",na.print="")      # K=3, n=50, g=1000

print(tab5,include.rownames=F, floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab6 = xtable(table2_other_ARI_35,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with moderate noise ($\\phi = 0.35$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:14",na.print="")      # K=3, n=50, g=1000

print(tab6,include.rownames=F,floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab7 = xtable(table2_other_ARI_50,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with moderately high noise ($\\phi = 0.50$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:15",na.print="")      # K=3, n=50, g=1000

print(tab7,include.rownames=F, floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

tab8 = xtable(table2_other_ARI_100,
              digits=2,
              table.placement="!h",
              caption="Effects of high/low simulated log means ($\\beta = 3.75$ and $6.50$) with very high noise ($\\phi = 1.00$) in simulated datasets on performance, compared to competing methods HC and KM.",
              label = "tab:16",na.print="")      # K=3, n=50, g=1000

print(tab8,include.rownames=F, floating.environment = "sidewaystable",
      sanitize.text.function=identity,add.to.row=list(pos=as.list(rws),command=col))

@


\begin{figure}
\begin{center}
\includegraphics[width=170mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/sim_bplots_ARI.png}
\end{center}
\caption{"Boxplots of ARI of competing methodsacross simulations at low ($\phi=0.15$, top-left), moderate ($\phi=0.35$, top-right), moderately high ($\phi=0.50$, bottom-left), and very high ($\phi=1.00$, bottom-right) noise.}
\label{fig:bplots}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=170mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/select_sim_bplots_ARI.png}
\end{center}
\caption{"Boxplots of ARI at fixed case of $K=6$, $\beta=6.5$, $LFC=1$, $n=100$, and $p_{disc}=0.05$ of competing methods at low ($\phi=0.15$, top-left), moderate ($\phi=0.35$, top-right), moderately high ($\phi=0.50$, bottom-left), and very high ($\phi=1.00$, bottom-right) noise.}
\label{fig:bplots2}
\end{figure}


We immediately notice the sporadic nature of the iCluster+ order selection (iK). It chooses anywhere from the range of orders searched ($K=2,...,7$). It is impossible to assess where the issue is originating from. Since the order selection threshold is arbitrary, it may be that this threshold should be better adapted to the dimensions of the data. It may also be that the Poisson assumption on the count data is not sufficient to account for the added noise. In any case, it is clear that order selection for iCluster+ is faulty. In fact, at correctly selected orders, iCluster+ seems to be relatively accurate in clustering. However, FSCseq still yields higher ARI values across all conditions, except when FSCseq chooses $K=1$ (since iCluster+ cannot take $K=1$ as input, it cannot be evaluated).

HC and KM both seem to select close to $K=2$. This is especially problematic for KM, since $K=1$ was not even searched for that method. Without an underlying distribution to explain the simulated LFC's and noise, neither HC nor KM distinguish between clusters well. It is important to note that the many methods used to select the order with HC often did not agree. We choose the order that the majority of the methods selected, but we found that many datasets yielded a wide range of values for the order. It seems that most of the methods used in NbClust do not handle noise very well.

Again, at the correct specified order, both HC and KM seem to perform well in clustering. Their performances increase with increased $n_k$ or LFC. We also noted from Table \ref{tab:4} however that increasing the noise from $\phi=0.5$ to $\phi=1$ significantly decreases the performance, even with correctly selected order of 2. In contrast, FSCseq handles the increase in noise much better, with just slight dips in clustering performance (ARI) corresponding to runs with incorrectly selected order ($\hat{K}$).

%%% g vs cl, CEM vs EM %%%
Next, we introduce some variants of our method. For one, we have so far restricted the simulations to contain gene-specific dispersions. It is not currently known whether a scheme with one dispersion parameter across all clusters for each gene adequately portrays real data. It may sometimes be more appropriate to introduce cluster-specific dispersion parameters to better fit the data, yielding more accurate estimates. However, this may also result in overfitting the data, which would cause our model to get stuck at a local maxima. One potential drawback that may result is that the order may be underestimated, as the extra dispersion parameters may cause the algorithm to favor a smaller number of clusters in the data.

Secondly, prior work has shown that the EM algorithm tends to converge to the local maximum, rather than the global maximum. Thus, this may result in the algorithm being "stuck" at less than ideal conditions. One way to prevent this is to replace the current E step with the classification E step. This variant of the E step introduces some randomness by drawing the posterior probabilities closer together, causing the algorithm to overcome local maxima through small perturbations of the clustering index. We use a simulated annealing method \citep{Rose1998,Si2013} to slowly wean off the noise-adding effects of the CEM, and revert to the original EM. \ref{tab:2} shows the results of these variants under simulated gene-specific and cluster-specific dispersions, respectively, as well as the analogous iCluster+ results. Results are based on 24 simulated datasets for each case.

<<xtable9,results=tex,echo=FALSE>>==
load("C:/Users/limdd/Documents/Research/Simulations/elasticSCAD/24sims_gvcl_EMvCEM/sim_res_gvcl_EMvCEM.RData")

tab9 = xtable(table2,
              digits=2,
              table.placement="!h",
              caption="Clustering, discovery, and prediction performance of variants of EM, as well as iCluster+ (iClust), average-linkage hierarchical clustering (HC), and K-medoids (KM). Each row represents the average across 24 different simulated datasets with true order $K=3$, $n_k=50$, 2000 genes, and 5\\% discriminatory genes with log2 fold change of 1.",
              label = "tab:17",na.print=""
              #,floating.environment = "table*"
              )      # K=3, n=50, g=1000
print(tab9,include.rownames=T, sanitize.text.function=identity)

@

(1) gEM is the EM with gene-specific dispersions, as before; (2) gCEM is the CEM with gene-specific dispersions; (3) clEM is the EM with cluster-specific dispersions; and (4) clCEM is the CEM with cluster-specific dispersions.The first term refers to the scheme by which the data was simulated: "g" for simulated gene-specific dispersions, and "cl" for simulated cluster-specific dispersions.

We notice that the cluster-specific runs of both EM and CEM were not able to correctly determine the order. Due to the additional parameters, the model becomes overfitted and prefers fewer parameters by selecting a smaller $K$. iCluster+ again grossly overestimates the order, in part due to the inability to automatize a heuristic "elbow point" determination of order. HC and KM seem to underestimate the order significantly, although simulating separate cluster-specific dispersions slightly increases this estimate. As far as clustering performance, the gEM and gCEM seems to outperform clEM and clCEM because of the misspecified order when allowing cluster-specific dispersions. However, we see that when the simulated dispersions were cluster-specific, the sensitivity and FPR of significant gene discovery were improved by clEM and clCEM over gEM and gCEM.

In FSCseq, the EM option chooses to search over numerous initializations with short EM runs, then perform a full run with the EM based on the optimal initialization. The CEM option simply uses CEM instead of the EM for the full run. Here, we see that the CEM seems to be performing slightly better than the EM in clustering. This is one of the advantages of the CEM, as it can help prevent the EM from being "stuck" at a local maximum. We found, however, that at higher dimensions, the CEM would often knock initializations that converged to the global maximum back to being stuck at a local maximum in the full run.

%%% 3.2 Real Data %%%
\subsection{Real Data}
We performed comparisons of FSCseq (EM), iCluster+, HC, and KM in two real datasets: The Cancer Genome Atlas (TCGA) Breast Cancer (BRCA) and TCGA Bladder Cancer (BLCA). Datasets and annotations were obtained from the National Cancer Institute GDC Portal \citep{Grossman2016}. In both datasets, we first pre-filtered samples based on estimated tumor purity and incidence of each annotated subtype. We also pre-filtered genes based on low normalized (corrected for sequencing depth) count and MAD scores.

We compared each clustering method with the annotated subtypes with ARI. Also, we analyzed the clustering performance by performing survival analysis with the logrank test. This test typically uses a Chi-square statistic to measure significance, which assumes large sample size. A very recent study showed that this large sample approximation is not appropriate in many genomic settings, and proposed using an empirical p-value based on a permutation test in order to gauge significance \citep{Rappoport2018}. In fact, results of said study revealed that the Chi-square approximation logrank test always yields more significant results than the permutation-based test. We run the large-sample approximation logrank test, and attempted to incorporate the permutation-based logrank test, providing p-values to measure significant differences in survival across clusters. We found that when the number of survival events in one derived cluster is too few, the permutation-based method would fail, as the test would often randomly sample clusters with zero survival outcomes for all but one group. We assert that given more ideal circumstances in which more samples can be included, the empirical p-value is a more accurate metric of the significance of the difference in survival across groups.

<Fisher's pval? Hazards ratios? Silhouette values?>

A recent study showed that the average silhouette value is robust to small sample size, and can be very indicative of degree of cluster separation in RNA-seq data \citep{Zhao2018}. But in cases with uneven samples per cluster, the average silhouette values can be skewed.

\subsubsection{TCGA Breast Cancer Dataset}

We performed our clustering analysis on The Cancer Genome Atlas (TCGA) breast cancer (BRCA) dataset. This dataset contained 1215 subjects and 21022 genes. Purity is known to be a very strong confounder for cancer genomic data. Thus, we narrowed down our analysis to only samples with estimated tumor purity greater than 0.9. We were left with 132 samples with 5 different subtypes: 53 luminal A, 38 luminal B, 32 basal-like, 6 HER2-enriched, and 2 normal-like. Due to the low incidence of the HER2-enriched and normal-like subtypes, we omitted these in our analysis. We performed our analysis on the remaining 124 samples with 3 distinct subtypes. Then, we filtered out genes with low count by excluding genes with MAD scores below the median MAD from our analysis, yielding 9062 total genes. We chose to be more liberal by selecting a higher threshold on the proportion of genes pre-selected via MAD (50\% rather than 20\% in our simulations) in order to help increase the sensitivity of keeping discriminatory genes in our analysis.

We performed clustering and feature selection on the resultant dataset of 124 samples and 9062 genes. Based on the results by Koboldt et al, we decided to expand the range of our order selection to $K=1, ..., 15$. We compared our clustering results with the subtypes that have been previously determined and annotated. These annotated subtypes are results based on the well-known PAM50 genes.

We also compared our method (EM) with iCluster+, HC, and KM. Results are given in Table \cref{tab:6}

<<xtable10,results=tex,echo=F>>=
load("C:/Users/limdd/Documents/Research/Real Data/TCGA BRCA/BRCA_compare_res.RData")

tab10 = xtable(summary_table[,1:6],digits=3,caption="ARI, average silhouette values (sil) and p-values from Log-Rank survival test with Chi-square approximation (LRpval) and with permutation-based empirical test (emppval), and the p-value of the Fisher's Exact test on the contingency table of survival events and cluster labels (fisherpval) of analyses performed on TCGA Breast Cancer dataset by FSCseq (EM) and competing methods compared to the annotated (anno).",
              label="tab:18",
              #table.placement="H",
              na.print=""
              #,floating.environment = "table*"
              )
print(tab10,sanitize.text.function=identity)

@

FSCseq was the only method to uncover the true order of $K=3$. iCluster+ drastically overestimated the order as $K=7$, while HC and KM both chose $K=2$. The average silhouette value seems to be higher for KM and HC than for the annotated clusters, iCluster+, or FSCseq. Although this may indicate better cluster separation of KM and HC, our analysis showed that silhouette values were very skewed in fewer samples per cluster. The Fisher's Exact test yielded insignificant results across all methods.

The permutation-based logrank test could not be performed in HC and KM due to the low number of survival events in one group, which caused the sampling to often yield only one group with survival events. Compared to both the iCluster+ and annotated clusters, the FSCseq clusters yielded p-values that were lower in both the Chi-square and permutation-based logrank tests. In fact, the empirical pvalue of FSCseq was the only value under $0.1$. This suggests a significant difference in survival outcomes only across clusters as partitioned by FSCseq.

Feature selection in FSCseq determined a total of 7228 genes to be discriminatory. \ref{fig:2} shows a heatmap of these genes, ordered by the derived clusters. Given the very small false positive rate in our simulations, we predict that many of these genes provide valuable information in differential expression across these clusters.

\begin{sidewaysfigure}
\includegraphics[width=250mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/BRCA_disc_HM.png}
\caption{Heatmap of derived discriminatory genes discovered by FSCseq on TCGA BRCA dataset. Cluster labels are annotated above, with derived clusters ("EM") and annotated clusters.}
\label{fig:2}
\end{sidewaysfigure}

Cluster 3 comprised mostly of Luminal A subtypes, with two Luminal B subtypes. Cluster 2 consisted of a mixture of Luminal A and Luminal B subtypes. The algorithm had a hard time distinguishing these two subtypes, suggesting strong similarities between the two subtypes. Cluster 1 contained all basal subtypes, mixed with two Luminal B subtypes. The basal subtype is the most distinct subtype of the three.

It has been widely known and accepted that the PAM50 genes are genes of significant interest in determining subtypes of cancer. We thus performed further analyses on just these PAM50 genes. Of note, the pre-filtering by MAD filtered out just 3 of the PAM50 genes due to low MAD value. Also, out of the 47 that made it past the pre-filtering step, our algorithm remarkably found 45 of them to be discriminatory across the derived clusters. This is important because the PAM50 genes were discovered by microarray platforms, and FSCseq is able to validate their significance via RNAseq. \ref{fig:3} shows the distribution of MAD scores of the PAM50 genes that were pre-filtered out, as well as the estimated log fold change across clusters for those PAM50 genes that were selected by our algorithm to be nondiscriminatory.

\begin{figure}
\begin{center}
\includegraphics[width=170mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/BRCA_MAD_LFC_PAM50.png}
\end{center}
\caption{(left) MAD scores of PAM50 genes, stratified by inclusion via MAD pre-filtering scheme; (right) Estimated LFC's of normalized counts across derived clusters}
\label{fig:3}
\end{figure}

The three PAM50 genes that were excluded by MAD pre-filtering were 'GRB7', 'MDM2', and 'ACTR3B', which yielded MAD values of $0.565$, $0.466$, and $0.464$ respectively. The median MAD value was $0.602$, so these genes were below the pre-filtering cut-off. Of the 47 PAM50 genes included in our analysis, the two genes that FSCseq found to be nondiscriminatory were 'ERBB2' and 'MMP11', which yielded estimated log2 fold changes of $0.346$ and $0.338$ across the derived clusters. Figure \ref{fig:4} is a heatmap of the 47 PAM50 genes that were included in our analysis. We see that the genes that FSCseq determined to be nondiscriminatory qualitatively do seem to be nondiscriminatory according to the heatmap.

\begin{figure}
\begin{center}
\includegraphics[width=180mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/BRCA_pam50_incl47_HM.png}
\end{center}
\caption{Heatmap of the 47 PAM50 genes included in analysis after pre-filtering, ordered by derived (EM) clusters. FSCseq variable selection determined genes 'ERBB2' and 'MMP11' to be nondiscriminatory}
\label{fig:4}
\end{figure}

\subsubsection{TCGA Bladder Cancer Dataset}

We also performed similar analyses on the TCGA Bladder Cancer dataset. This dataset contained 427 samples and 21022 genes, with annotated subtypes based on a study done by Robertson et al. Because of the smaller sample size (compared to the BRCA dataset), we included in our analysis samples whose estimated tumor purity was greater 0.8. This yielded 104 samples with 5 subtypes: 80 Luminal-papillary, 11 Neuronal, 8 Basal-squamous, 4 Luminal, and 1 Luminal-infiltrated. Due to the extremely low incidence of the Luminal and Luminal-infiltrated subtypes, we excluded them in our analysis, leaving us with 99 samples of 3 distinct subtypes. As before, we filtered just the genes with the top 50 quantile MAD scores, leaving 8874 genes in the analysis.

Robertson mentions the lower purity levels of the luminal-infiltrated and basal-squamous subtypes, and the higher purity levels of the luminal-papillary subtype. This was evident in our pre-filtering procedure, as 85 of the 86 annotated samples with luminal-infiltrated subtype and 139 out of 147 basal-squamous samples with basal-squamous subtype fell short of our purity threshold of 0.8, while 80 of the 144 annotated samples with luminal-papillary subtype had purity estimates greater than our threshold.

<<xtable11,results=tex,echo=F>>=
load("C:/Users/limdd/Documents/Research/Real Data/TCGA BLCA/BLCA_compare_res.RData")

tab11 = xtable(summary_table[,1:6],digits=3,caption="ARI, average silhouette values (sil) and p-values from Log-Rank survival test with Chi-square approximation (LRpval) and with permutation-based empirical test (emppval), and the p-value of the Fisher's Exact test on the contingency table of survival events and cluster labels (fisherpval) of analyses performed on TCGA Bladder Cancer (BLCA) dataset by FSCseq (EM), iCluster+, HC, and KM.",
              label="tab:19",
              #table.placement="H",
              na.print=""
              #,floating.environment = "table*"
              )
print(tab11,sanitize.text.function=identity)

@

% EDIT FROM HERE %
The FSCseq order selection step yielded $K=4$: one extra cluster than the annotated. This over-estimation of the order is due to the lower purity threshold on the BLCA samples, as compared to the BRCA samples. Regardless of the order misspecification, the Chi-square approximation logrank p-value of the EM clusters was $0.067$, which was significantly lower than the annotated clusters' p-value of $0.567$. iCluster+ overspecified the order further as $K=5$ and showed a logrank p-value of $0.126$, which was better than the annotations, but worse than FSCseq. The empirical p-value was able to be derived only in FSCseq and iCluster+ clusters, and FSCseq outperformed iCluster+. Although HC and KM both chose $K=2$ again, as in the BRCA dataset, the KM clusters actually yielded a smaller p-value than the annotated clusters. Also, although the HC yielded the highest average silhouette value, we found that the clustering was extremely uneven, with 96 samples in Cluster 1 and just three samples in Cluster 2. Additionally, the logrank test yielded the highest p-value for the HC clusters. This highlights the limitations of the silhouette value in groups with very small sample size, as the silhouette value will be highly variable and dependent on a few data points.

Our method determined a total of 7726 genes to be discriminatory. \ref{fig:5} shows a heatmap of these genes, ordered by the derived clusters. 

\begin{sidewaysfigure}
\includegraphics[width=250mm]{C:/Users/limdd/Documents/Research/Sweave/Project1/BLCA_disc_HM.png}
\caption{Heatmap of derived discriminatory genes discovered by FSCseq on TCGA BLCA dataset. Cluster labels are annotated above, with derived clusters ("EM") and annotated clusters.}
\label{fig:5}
\end{sidewaysfigure}

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% 4. DISCUSSION %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{sec:disc}

Our findings from the simulations and real data applications give evidence to the usefulness of our method. In our simulations, we found that the feature selection and clustering performance of FSCseq were extremely good and robust even at relatively high levels of noise. Analysis on the real data showed that clusters via FSCseq were more significant than the annotated clusters in survival. These annotations were typically done based on significant genes that were known a priori, as well as derived by integrative methods that drew information from other genomic datasets besides gene expression. Despite this, we showed that FSCseq is able to perform better using just raw RNAseq gene expression data. Moreover, of the 47 PAM50 genes included in analysis, FSCseq was able to correctly identify 45 of these genes as discriminatory. As these PAM50 genes were found to be significant driving genes via microarray platforms, this emphasizes the reproducibility and comparability of RNAseq to microarray. As RNAseq becomes more widely used, we posit that this platform can be used to improve upon known significant driving genes such as PAM50, and even to discover novel driving genes in the future.

One way by which this method can be drastically improved is by adjusting for tumor purity in the model. Because of the fluctuating tumor purity levels in real datasets, we were forced to filter out all but very high purity samples. In doing so, we lost a significant amount of information, especially in the case of the BLCA dataset, and we were often faced with low sample size issues. It was clear that the lower purity samples added more noise into the dataset; because of the higher noise in the BLCA dataset ($purity = 0.8$) compared to the BRCA dataset ($purity = 0.9$), FSCseq slightly overestimated the number of clusters in the BLCA dataset, whereas it correctly identified the order in the BRCA dataset. Ideally, a framework can be developed to seamlessly integrate estimated purity grades so we minimize the loss of information due to filtering.

Secondly, our regression-like framework allows us to easily adjust for confounders. This was beyond the scope of this paper, but adding covariates like age and gender may help improve our method by correcting for potential sources of confounding. This can be generalized further to adjust for batch effects, or potentially even purity levels.

Third, the MAD pre-filtering method we imposed on the features often showed significantly lower sensitivity at higher levels of noise in our simulations. This pre-filtering step is vital, as FSCseq is unable to deal with any discriminatory genes that are pre-filtered out and not included in the model. However, omitting the pre-filtering step can decrease order selection performance, as the proportion of discriminatory genes will be smaller and the model will prefer fewer clusters due to the large number of nondiscriminatory genes. A future direction can focus on refining the pre-filtering step, adjusting the MAD method to account for different levels of purity and other potential sources of noise. Otherwise, a goodness of fit statistic of an intercept-only model assuming some level of noise may be able to rank genes, like the MAD method we employ. We leave it as a future direction to further assess the pre-filtering step.

Fourth, currently we circumvent the widely-known issue of the EM algorithm converging to the local maximum (instead of the global maximum) by searching over many random initializations with short EM runs, then performing a final longer EM run with the optimal initialization selected by BIC. This is very computationally expensive, and can be improved to be more efficient. Rather than randomly sampling initializations, one can make a smaller number of more informed initializations based on existing clustering methods. Alternatively, one can perform clustering on different subsets of the entire feature space, and search over the resulting clusters.

Fifth, FSCseq is novel in its ability to assign posterior probabilities that can be used to assign future patients into existing clusters based on an already fitted model. However, this requires a way to adjust new samples' expression profiles for sequencing depth. A naive approach would be to re-estimate the size factors by concatenating the training and test datasets together. Otherwise, one can compare the expression profile of the new patient with the training set, and compute the new patient's size factor by using an average of the training set size factors weighted by similarity to each existing sample.

Lastly, we assume no gene-to-gene interaction in our model for simplicity. Allowing for correlation between genes may help improve performance, but would likely result in a much more computationally complex model. Although a finite mixture model is very computationally extensive, it may be worth introducing gene interaction depending on the degree of improvement in performance.

\backmatter
%  This section is optional.  Here is where you will want to cite
%  grants, people who helped with the paper, etc.  But keep it short!

\section*{Acknowledgements}

Special thanks to my co-advisors Dr. Naim Rashid and Dr. Joseph Ibrahim
This research was supported by NIH grant 5T32CA106209-13.\vspace*{-8pt}

%  If your paper refers to supplementary web material, then you MUST
%  include this section!!  See Instructions for Authors at the journal
%  website http://www.biometrics.tibs.org

% \section*{Supplementary Materials}
% 
% Web Appendix A, referenced in Section~\ref{s:model}, is available with
% this paper at the Biometrics website on Wiley Online
% Library.\vspace*{-8pt}

\section{References}
%  Here, we create the bibliographic entries manually, following the
%  journal style.  If you use this method or use natbib, PLEASE PAY
%  CAREFUL ATTENTION TO THE BIBLIOGRAPHIC STYLE IN A RECENT ISSUE OF
%  THE JOURNAL AND FOLLOW IT!  Failure to follow stylistic conventions
%  just lengthens the time spend copyediting your paper and hence its
%  position in the publication queue should it be accepted.

%  We greatly prefer that you incorporate the references for your
%  article into the body of the article as we have done here 
%  (you can use natbib or not as you choose) than use BiBTeX,
%  so that your article is self-contained in one file.
%  If you do use BiBTeX, please use the .bst file that comes with 
%  the distribution.  In this case, replace the thebibliography
%  environment below by 

\bibliographystyle{biom}
\bibliography{Proj1}
%\bibliography{proj1bib}

% \appendix
%  To get the journal style of heading for an appendix, mimic the following.
% 
% \section{}
% \subsection{Title of appendix}
% 
% Put your short appendix here.  Remember, longer appendices are
% possible when presented as Supplementary Web Material.  Please 
% review and follow the journal policy for this material, available
% under Instructions for Authors at \texttt{http://www.biometrics.tibs.org}.

\label{lastpage}

\end{document}