for(c in 1:k){
dat_gc<-dat_g[dat_g[,"clusts"]==c,]
beta[c]<-log(glm(dat_gc[,"count"] ~ 1 + offset(log(dat_gc[,"size_factors"])), weights=dat_gc[,"weights"])$coef)
}
# break condition for IRLS
if(i>1){
if(sum((temp[i,]-temp[i-1,])^2)<1E-7){
coefs[j,]<-beta
break
}
}
if(i==maxit_IRLS){
coefs[j,]<-beta
}
}
}
for(c in 1:k){
pi[c]=mean(wts[c,])
if(pi[c]<1E-6){
warning(paste("cluster proportion", c, "close to 0"))
pi[c]=1E-6
} # lowerbound for pi
if(pi[c]>(1-1E-6)){
warning(paste("cluster proportion", c, "close to 1"))
pi[c]=(1-1E-6)
} # upperbound for pi
}
l<-matrix(rep(0,times=k*n),nrow=k)
for(i in 1:n){
for(c in 1:k){
l[c,i]<-sum(dpois(y[,i],lambda=exp(coefs[,c])*size_factors[i],log=TRUE))    # posterior log like, include size_factor of subj
}
}
pt1<-(log(pi)%*%rowSums(wts))
pt2<-sum(wts*l)
Q[a]<-pt1+pt2
if(a>10){if(abs(Q[a]-Q[a-10])<1E-5) {
finalwts<-wts
break
}}
l
coefs
pi
logdenom = apply(log(pi) + l, 2,logsumexpc)
for(c in 1:k){
wts[c,]<-exp(log(pi[c])+l[c,]-logdenom)
}
wts
if(any(rowSums(wts)==0)){
print(paste("Empty cluster when K =",k,". Choose smaller K"))
break
}
rowSums(wts)
for(a in 1:maxit){
# M step
dat[,"weights"]<-rep(as.vector(wts),times=g) # update weights column in dat
# IRWLS:
maxit_IRLS=100
beta<-rep(0,times=k)
for(j in 1:g){
if(a>1) {beta<-coefs[j,]} else {
for(c in 1:k){
beta[c]<-log(mean(as.numeric(y[j,cls==c])))
}
}   # initialization of beta = gene mean
temp<-matrix(rep(0,times=maxit_IRLS*k),nrow=maxit_IRLS)    # to test for convergence of IRLS
dat_g<-dat[dat[,"g"]==j,]                                  # subset just the j'th gene
for(i in 1:maxit_IRLS){
temp[i,]<-beta
for(c in 1:k){
dat_gc<-dat_g[dat_g[,"clusts"]==c,]
beta[c]<-log(glm(dat_gc[,"count"] ~ 1 + offset(log(dat_gc[,"size_factors"])), weights=dat_gc[,"weights"])$coef)
}
# break condition for IRLS
if(i>1){
if(sum((temp[i,]-temp[i-1,])^2)<1E-7){
coefs[j,]<-beta
break
}
}
if(i==maxit_IRLS){
coefs[j,]<-beta
}
}
}
# update on pi_hat
for(c in 1:k){
pi[c]=mean(wts[c,])
if(pi[c]<1E-6){
warning(paste("cluster proportion", c, "close to 0"))
pi[c]=1E-6
} # lowerbound for pi
if(pi[c]>(1-1E-6)){
warning(paste("cluster proportion", c, "close to 1"))
pi[c]=(1-1E-6)
} # upperbound for pi
}
# log(f_k(y_i)): summing over all j
l<-matrix(rep(0,times=k*n),nrow=k)
for(i in 1:n){
for(c in 1:k){
l[c,i]<-sum(dpois(y[,i],lambda=exp(coefs[,c])*size_factors[i],log=TRUE))    # posterior log like, include size_factor of subj
}
}
# store and check stopping criterion
pt1<-(log(pi)%*%rowSums(wts))
pt2<-sum(wts*l)
Q[a]<-pt1+pt2
if(a>10){if(abs(Q[a]-Q[a-10])<1E-5) {
finalwts<-wts
break
}}
# E step
# update on weights
logdenom = apply(log(pi) + l, 2,logsumexpc)
for(c in 1:k){
wts[c,]<-exp(log(pi[c])+l[c,]-logdenom)
}
if(a==maxit){finalwts<-wts}
# print(pi) # print estimated cluster proportions
if(any(rowSums(wts)==0)){
print(paste("Empty cluster when K =",k,". Choose smaller K"))
break
}
}
wts
coefs
k=4
n<-ncol(y)
g<-nrow(y)
vect_y<-as.vector(t(y))
new_y<-rep(vect_y,each=k) # flatten and multiply each count by number of clusters
new_size_factors<-rep(rep(size_factors,each=k),times=g)    ############## corresponding size factors for each entry in trans. data #
gene<-rep(1:g,each=k*n) # gene for each corresponding new_y
clusts<-matrix(rep(t(diag(k)),times=n*g),byrow=TRUE,ncol=k) # cluster indicators
d<-dist(t(y))                               ##Euclidean distance##
cls<-cutree(model,k=k)
model<-hclust(d,method="complete")       # hierarchical clustering
wts<-matrix(rep(0,times=k*ncol(y)),nrow=k)
for(c in 1:k){
wts[c,]=(cls==c)^2
}
vect_wts<-rep(as.vector(wts),times=g)
clust_index<-rep((1:k),times=n*g)
dat<-cbind(new_y,clusts,clust_index,gene,vect_wts,new_size_factors) # this is k*g*n rows. cols: count, indicator for cl1, cl2, cl3, genes, wts
colnames(dat)[1]<-c("count")
colnames(dat)[(k+2):ncol(dat)]<-c("clusts","g","weights","size_factors")
finalwts<-matrix(rep(0,times=k*ncol(y)),nrow=k)
maxit = 100
coefs<-matrix(rep(0,times=g*k),nrow=g)
pi<-rep(0,times=k)
Q<-rep(0,times=maxit)
for(a in 1:maxit){
# M step
dat[,"weights"]<-rep(as.vector(wts),times=g) # update weights column in dat
# IRWLS:
maxit_IRLS=100
beta<-rep(0,times=k)
for(j in 1:g){
if(a>1) {beta<-coefs[j,]} else {
for(c in 1:k){
beta[c]<-log(mean(as.numeric(y[j,cls==c])))
}
}   # initialization of beta = gene mean
temp<-matrix(rep(0,times=maxit_IRLS*k),nrow=maxit_IRLS)    # to test for convergence of IRLS
dat_g<-dat[dat[,"g"]==j,]                                  # subset just the j'th gene
for(i in 1:maxit_IRLS){
temp[i,]<-beta
for(c in 1:k){
dat_gc<-dat_g[dat_g[,"clusts"]==c,]
beta[c]<-log(glm(dat_gc[,"count"] ~ 1 + offset(log(dat_gc[,"size_factors"])), weights=dat_gc[,"weights"])$coef)
}
# break condition for IRLS
if(i>1){
if(sum((temp[i,]-temp[i-1,])^2)<1E-7){
coefs[j,]<-beta
break
}
}
if(i==maxit_IRLS){
coefs[j,]<-beta
}
}
}
# update on pi_hat
for(c in 1:k){
pi[c]=mean(wts[c,])
if(pi[c]<1E-6){
warning(paste("cluster proportion", c, "close to 0"))
pi[c]=1E-6
} # lowerbound for pi
if(pi[c]>(1-1E-6)){
warning(paste("cluster proportion", c, "close to 1"))
pi[c]=(1-1E-6)
} # upperbound for pi
}
# log(f_k(y_i)): summing over all j
l<-matrix(rep(0,times=k*n),nrow=k)
for(i in 1:n){
for(c in 1:k){
l[c,i]<-sum(dpois(y[,i],lambda=exp(coefs[,c])*size_factors[i],log=TRUE))    # posterior log like, include size_factor of subj
}
}
# store and check stopping criterion
pt1<-(log(pi)%*%rowSums(wts))
pt2<-sum(wts*l)
Q[a]<-pt1+pt2
if(a>10){if(abs(Q[a]-Q[a-10])<1E-5) {
finalwts<-wts
break
}}
# E step
# update on weights
logdenom = apply(log(pi) + l, 2,logsumexpc)
for(c in 1:k){
wts[c,]<-exp(log(pi[c])+l[c,]-logdenom)
}
if(a==maxit){finalwts<-wts}
# print(pi) # print estimated cluster proportions
if(any(rowSums(wts)==0)){
print(paste("Empty cluster when K =",k,". Choose smaller K"))
break
}
}
wts
coefs
wts
View(coefs)
g=1
pi=c(0.3,0.3,0.2,0.2)
sigma=diag(k)
b=matrix(rep(0,times=k*g),nrow=g,byrow=TRUE) # initialize betas
b[1:500,]<-matrix(rep(c(10,10.5,11,11.5),times=500),nrow=500,byrow=TRUE) # Fixing the means to ensure no nondiscriminatory cases
b[1:250,]<-matrix(rep(c(9,9,9,9),times=250),nrow=250)
g=2
b[1,]<-c(10,10.5,11,11.5)
b=matrix(rep(0,times=k*g),nrow=g,byrow=TRUE) # initialize betas
b[1,]<-c(10,10.5,11,11.5)
b[2,]<-c(9,9,9,9)
simulate_data=function(n,k,g,init_pi,b){
y<-matrix(rep(0,times=g*n),nrow=g)      # initialize count matrix gxn #
# Prepare new flattened data
z = rmultinom(n,1,init_pi)
# while(any(rowSums(z)==0)){z=rmultinom(n,1,init_pi)}   # makes sure that no one cluster simulated @ 0 membership (only good for simulations)
for(j in 1:g){
for(c in 1:k){
y[j,z[c,]==1] = rpois(sum(z[c,]==1), lambda = sim_size_factors[z[c,]==1]*exp(b[j,c]))
}
}
result<-list(y=y,z=z)
return(result)
}
sim.dat<-simulate_data(n=n,k=k,g=g,init_pi=pi,b=b)
y<-sim.dat$y
z<-sim.dat$z
true_clusters<-rep(0,times=n)
for(i in 1:n){
true_clusters[i]<-which(z[,i]==1)
}
size_factors
sim_size_factors
source("C:/Users/David/Desktop/Research/GitHub/EM/unpenalized Pan EM.R")
K_search=c(2:15)
list_BIC=matrix(0,nrow=length(K_search),ncol=2)
list_BIC[,1]=K_search
for(aa in 1:nrow(list_BIC)){
list_BIC[aa,2]<-EM(y=y,k=list_BIC[aa,1],size_factors=size_factors)$BIC
print(list_BIC[aa,])
}
k=2
n<-ncol(y)
g<-nrow(y)
vect_y<-as.vector(t(y))
new_y<-rep(vect_y,each=k) # flatten and multiply each count by number of clusters
new_size_factors<-rep(rep(size_factors,each=k),times=g)    ############## corresponding size factors for each entry in trans. data #
gene<-rep(1:g,each=k*n) # gene for each corresponding new_y
clusts<-matrix(rep(t(diag(k)),times=n*g),byrow=TRUE,ncol=k) # cluster indicators
d<-dist(t(y))                               ##Euclidean distance##
model<-hclust(d,method="complete")       # hierarchical clustering
cls<-cutree(model,k=k)
cls
row_names<-paste("gene",seq(g))
col_names<-paste("subj",seq(n))
cts<-as.matrix(y)
rownames(cts)<-row_names
colnames(cts)<-col_names
rownames(coldata)<-colnames(cts)
coldata<-matrix(paste("cl",true_clusters,sep=""),nrow=n)
colnames(coldata)<-"cluster"
dds<-DESeqDataSetFromMatrix(countData = cts,
colData = coldata,
design = ~ 1)
DESeq_dds<-DESeq(dds)
size_factors<-estimateSizeFactors(dds)$sizeFactor
norm_y<-counts(DESeq_dds,normalized=TRUE)
n<-ncol(y)
g<-nrow(y)
vect_y<-as.vector(t(y))
new_y<-rep(vect_y,each=k) # flatten and multiply each count by number of clusters
new_size_factors<-rep(rep(size_factors,each=k),times=g)    ############## corresponding size factors for each entry in trans. data #
gene<-rep(1:g,each=k*n) # gene for each corresponding new_y
clusts<-matrix(rep(t(diag(k)),times=n*g),byrow=TRUE,ncol=k) # cluster indicators
d<-as.dist(1-cor(norm_y, method="spearman"))  ##Spearman correlation distance w/ log transform##
model<-hclust(d,method="complete")       # hierarchical clustering
cls<-cutree(model,k=k)
cls
source("C:/Users/David/Desktop/Research/GitHub/EM/unpenalized Pan EM.R")
K_search=c(2:15)
list_BIC=matrix(0,nrow=length(K_search),ncol=2)
list_BIC[,1]=K_search
for(aa in 1:nrow(list_BIC)){
list_BIC[aa,2]<-EM(y=y,k=list_BIC[aa,1],size_factors=size_factors)$BIC
print(list_BIC[aa,])
}
wts<-matrix(rep(0,times=k*ncol(y)),nrow=k)
for(c in 1:k){
wts[c,]=(cls==c)^2
}
vect_wts<-rep(as.vector(wts),times=g)
clust_index<-rep((1:k),times=n*g)
dat<-cbind(new_y,clusts,clust_index,gene,vect_wts,new_size_factors) # this is k*g*n rows. cols: count, indicator for cl1, cl2, cl3, genes, wts
colnames(dat)[1]<-c("count")
colnames(dat)[(k+2):ncol(dat)]<-c("clusts","g","weights","size_factors")
finalwts<-matrix(rep(0,times=k*ncol(y)),nrow=k)
maxit = 100
coefs<-matrix(rep(0,times=g*k),nrow=g)
pi<-rep(0,times=k)
Q<-rep(0,times=maxit)
for(a in 1:maxit){
# M step
dat[,"weights"]<-rep(as.vector(wts),times=g) # update weights column in dat
# IRWLS:
maxit_IRLS=100
beta<-rep(0,times=k)
for(j in 1:g){
if(a>1) {beta<-coefs[j,]} else {
for(c in 1:k){
beta[c]<-log(mean(as.numeric(y[j,cls==c])))
}
}   # initialization of beta = gene mean
temp<-matrix(rep(0,times=maxit_IRLS*k),nrow=maxit_IRLS)    # to test for convergence of IRLS
dat_g<-dat[dat[,"g"]==j,]                                  # subset just the j'th gene
for(i in 1:maxit_IRLS){
temp[i,]<-beta
for(c in 1:k){
dat_gc<-dat_g[dat_g[,"clusts"]==c,]
beta[c]<-log(glm(dat_gc[,"count"] ~ 1 + offset(log(dat_gc[,"size_factors"])), weights=dat_gc[,"weights"])$coef)
}
# break condition for IRLS
if(i>1){
if(sum((temp[i,]-temp[i-1,])^2)<1E-7){
coefs[j,]<-beta
break
}
}
if(i==maxit_IRLS){
coefs[j,]<-beta
}
}
}
# update on pi_hat
for(c in 1:k){
pi[c]=mean(wts[c,])
if(pi[c]<1E-6){
warning(paste("cluster proportion", c, "close to 0"))
pi[c]=1E-6
} # lowerbound for pi
if(pi[c]>(1-1E-6)){
warning(paste("cluster proportion", c, "close to 1"))
pi[c]=(1-1E-6)
} # upperbound for pi
}
# log(f_k(y_i)): summing over all j
l<-matrix(rep(0,times=k*n),nrow=k)
for(i in 1:n){
for(c in 1:k){
l[c,i]<-sum(dpois(y[,i],lambda=exp(coefs[,c])*size_factors[i],log=TRUE))    # posterior log like, include size_factor of subj
}
}
# store and check stopping criterion
pt1<-(log(pi)%*%rowSums(wts))
pt2<-sum(wts*l)
Q[a]<-pt1+pt2
if(a>10){if(abs(Q[a]-Q[a-10])<1E-5) {
finalwts<-wts
break
}}
# E step
# update on weights
logdenom = apply(log(pi) + l, 2,logsumexpc)
for(c in 1:k){
wts[c,]<-exp(log(pi[c])+l[c,]-logdenom)
}
if(a==maxit){finalwts<-wts}
# print(pi) # print estimated cluster proportions
if(any(rowSums(wts)==0)){
print(paste("Empty cluster when K =",k,". Choose smaller K"))
break
}
}
coefs<-matrix(rep(0,times=g*k),nrow=g)
pi<-rep(0,times=k)
Q<-rep(0,times=maxit)
dat[,"weights"]<-rep(as.vector(wts),times=g) # update weights column in dat
maxit_IRLS=100
beta<-rep(0,times=k)
a=1
dat[,"weights"]<-rep(as.vector(wts),times=g) # update weights column in dat
maxit_IRLS=100
beta<-rep(0,times=k)
j=1
if(a>1) {beta<-coefs[j,]} else {
for(c in 1:k){
beta[c]<-log(mean(as.numeric(y[j,cls==c])))
}
}   # initialization of beta = gene mean
temp<-matrix(rep(0,times=maxit_IRLS*k),nrow=maxit_IRLS)    # to test for convergence of IRLS
dat_g<-dat[dat[,"g"]==j,]                                  # subset just the j'th gene
temp
beta
i=1
temp[i,]<-beta
for(c in 1:k){
dat_gc<-dat_g[dat_g[,"clusts"]==c,]
beta[c]<-log(glm(dat_gc[,"count"] ~ 1 + offset(log(dat_gc[,"size_factors"])), weights=dat_gc[,"weights"])$coef)
}
wts
wts<-matrix(rep(0,times=k*ncol(y)),nrow=k)
for(c in 1:k){
wts[c,]=(cls==c)^2
}
vect_wts<-rep(as.vector(wts),times=g)
clust_index<-rep((1:k),times=n*g)
dat<-cbind(new_y,clusts,clust_index,gene,vect_wts,new_size_factors) # this is k*g*n rows. cols: count, indicator for cl1, cl2, cl3, genes, wts
colnames(dat)[1]<-c("count")
colnames(dat)[(k+2):ncol(dat)]<-c("clusts","g","weights","size_factors")
finalwts<-matrix(rep(0,times=k*ncol(y)),nrow=k)
maxit = 100
coefs<-matrix(rep(0,times=g*k),nrow=g)
pi<-rep(0,times=k)
Q<-rep(0,times=maxit)
dat[,"weights"]<-rep(as.vector(wts),times=g) # update weights column in dat
maxit_IRLS=100
beta<-rep(0,times=k)
if(a>1) {beta<-coefs[j,]} else {
for(c in 1:k){
beta[c]<-log(mean(as.numeric(y[j,cls==c])))
}
}   # initialization of beta = gene mean
temp<-matrix(rep(0,times=maxit_IRLS*k),nrow=maxit_IRLS)    # to test for convergence of IRLS
dat_g<-dat[dat[,"g"]==j,]                                  # subset just the j'th gene
i=1
temp[i,]<-beta
for(c in 1:k){
dat_gc<-dat_g[dat_g[,"clusts"]==c,]
beta[c]<-log(glm(dat_gc[,"count"] ~ 1 + offset(log(dat_gc[,"size_factors"])), weights=dat_gc[,"weights"])$coef)
}
beta
source("C:/Users/David/Desktop/Research/GitHub/EM/unpenalized Pan EM.R")
K_search=c(2:15)
list_BIC=matrix(0,nrow=length(K_search),ncol=2)
list_BIC[,1]=K_search
for(aa in 1:nrow(list_BIC)){
list_BIC[aa,2]<-EM(y=y,k=list_BIC[aa,1],size_factors=size_factors)$BIC
print(list_BIC[aa,])
}
n=20
k=4
g=500
pi=c(0.3,0.3,0.2,0.2)
sigma=diag(k)
b=matrix(rep(0,times=k*g),nrow=g,byrow=TRUE) # initialize betas
b[1:500,]<-matrix(rep(c(10,10.5,11,11.5),times=500),nrow=500,byrow=TRUE) # Fixing the means to ensure no nondiscriminatory cases
b[1:250,]<-matrix(rep(c(9,9,9,9),times=250),nrow=250)
sim_size_factors<-seq(from=0.75, to=2, length.out=n)
simulate_data=function(n,k,g,init_pi,b){
y<-matrix(rep(0,times=g*n),nrow=g)      # initialize count matrix gxn #
# Prepare new flattened data
z = rmultinom(n,1,init_pi)
# while(any(rowSums(z)==0)){z=rmultinom(n,1,init_pi)}   # makes sure that no one cluster simulated @ 0 membership (only good for simulations)
for(j in 1:g){
for(c in 1:k){
y[j,z[c,]==1] = rpois(sum(z[c,]==1), lambda = sim_size_factors[z[c,]==1]*exp(b[j,c]))
}
}
result<-list(y=y,z=z)
return(result)
}
sim.dat<-simulate_data(n=n,k=k,g=g,init_pi=pi,b=b)
y<-sim.dat$y
z<-sim.dat$z
true_clusters<-rep(0,times=n)
for(i in 1:n){
true_clusters[i]<-which(z[,i]==1)
}
size_factors<-sim_size_factors
source("C:/Users/David/Desktop/Research/GitHub/EM/unpenalized Pan EM.R")
K_search=c(2:15)
list_BIC=matrix(0,nrow=length(K_search),ncol=2)
list_BIC[,1]=K_search
for(aa in 1:nrow(list_BIC)){
list_BIC[aa,2]<-EM(y=y,k=list_BIC[aa,1],size_factors=size_factors)$BIC
print(list_BIC[aa,])
}
source("C:/Users/David/Desktop/Research/GitHub/EM/unpenalized Pan EM.R")
K_search=c(2:15)
list_BIC=matrix(0,nrow=length(K_search),ncol=2)
list_BIC[,1]=K_search
for(aa in 1:nrow(list_BIC)){
list_BIC[aa,2]<-EM(y=y,k=list_BIC[aa,1],size_factors=size_factors)$BIC
print(list_BIC[aa,])
}
